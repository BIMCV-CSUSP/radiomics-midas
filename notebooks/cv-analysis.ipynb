{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "\n",
    "from pathlib import Path\n",
    "from radiomics import imageoperations\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path(\"..\").resolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midas_img_relation = pd.read_csv(\n",
    "    root_dir.joinpath(\"data\", \"filtered_midas900_t2w.csv\"), sep=\",\"\n",
    ")\n",
    "midas_img_relation[\"Subject_MIDS\"] = midas_img_relation[\"Image\"].map(\n",
    "    lambda x: x.split(\"/\")[8]\n",
    ")\n",
    "midas_img_relation[\"Session_MIDS\"] = midas_img_relation[\"Image\"].map(\n",
    "    lambda x: x.split(\"/\")[9]\n",
    ")\n",
    "midas_img_relation[\"Subject_XNAT\"] = midas_img_relation[\"Subject_MIDS\"].map(\n",
    "    lambda x: f\"ceibcs_S{int(x.split('sub-S')[1])}\"\n",
    ")\n",
    "midas_img_relation[\"Session_XNAT\"] = midas_img_relation[\"Session_MIDS\"].map(\n",
    "    lambda x: f\"ceibcs_E{int(x.split('ses-E')[1])}\"\n",
    ")\n",
    "midas_img_relation[\"Image\"] = midas_img_relation[\"Image\"].map(\n",
    "    lambda x: x.replace(\"mnt\", \"mnt/ceib\")\n",
    ")\n",
    "midas_img_relation[\"Mask\"] = midas_img_relation[\"Mask\"].map(\n",
    "    lambda x: x.replace(\"mnt\", \"mnt/ceib\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(\n",
    "    root_dir.joinpath(\"data\", \"midasdisclabelsJDCarlos.csv\"), sep=\",\"\n",
    ")\n",
    "labels_df.dropna(inplace=True)\n",
    "labels_df.rename(\n",
    "    columns={\"subject_ID\": \"Subject_XNAT\", \"ID\": \"Session_XNAT\"}, inplace=True\n",
    ")\n",
    "\n",
    "id_labels = labels_df.merge(midas_img_relation, on=[\"Subject_XNAT\", \"Session_XNAT\"])\n",
    "id_labels.rename(\n",
    "    columns={\n",
    "        \"L5-S\": \"1\",\n",
    "        \"L4-L5\": \"2\",\n",
    "        \"L3-L4\": \"3\",\n",
    "        \"L2-L3\": \"4\",\n",
    "        \"L1-L2\": \"5\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bimcv_aikit.data.genetic_train_test_split import separate_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_csv = separate_dataset(\n",
    "    id_labels,\n",
    "    column_subjects=\"Subject_XNAT\",\n",
    "    column_classes=\"2\",\n",
    "    new_column_name=\"Partition\",\n",
    "    label_partitions=[\"train\", \"val\", \"test\"],\n",
    "    label_percentages=[0.7, 0.1, 0.2],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_csv.to_csv(\n",
    "    root_dir.joinpath(\"data\", \"filtered_midas900_t2w_partition.csv\"), index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_and_masks(img_path, mask_path):\n",
    "    image = nib.load(img_path)\n",
    "    mask = nib.load(mask_path)\n",
    "    image_data = image.get_fdata()\n",
    "    mask_data = mask.get_fdata()\n",
    "\n",
    "    center_slice = image_data.shape[2] // 2\n",
    "    unique_labels = np.unique(mask_data.ravel())\n",
    "\n",
    "    _, axs = plt.subplots(1, 3, figsize=(12, 12))\n",
    "    for i, slice in enumerate(range(center_slice - 1, center_slice + 2)):\n",
    "        axs[i].imshow(image_data[:, :, slice], cmap=\"gray\")\n",
    "        im = axs[i].imshow(\n",
    "            mask_data[:, :, slice],\n",
    "            cmap=\"jet\",\n",
    "            alpha=np.where(mask_data[:, :, slice] == 0, 0, 0.3),\n",
    "        )\n",
    "        axs[i].grid(False)\n",
    "        axs[i].axis(\"off\")\n",
    "    colors = [im.cmap(im.norm(value)) for value in unique_labels]\n",
    "    patches = [\n",
    "        mpatches.Patch(color=colors[i], label=f\"{unique_labels[i]}\")\n",
    "        for i in range(len(unique_labels))\n",
    "    ]\n",
    "    plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "show_image_and_masks(\n",
    "    midas_img_relation.iloc[index][\"Image\"], midas_img_relation.iloc[index][\"Mask\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheckMaskVol(transforms.MapTransform):\n",
    "    def __init__(\n",
    "        self,\n",
    "        keys=[\"image\", \"mask\"],\n",
    "        minimum_roi_dimensions: int = 3,\n",
    "        minimum_roi_size: int = 1000,\n",
    "    ):\n",
    "        super().__init__(keys)\n",
    "        self.minimum_roi_dimensions = minimum_roi_dimensions\n",
    "        self.minimum_roi_size = minimum_roi_size\n",
    "\n",
    "    def __call__(self, x):\n",
    "        image = sitk.ReadImage(x[self.keys[0]])\n",
    "        mask = sitk.ReadImage(x[self.keys[1]])\n",
    "        labels = np.unique(sitk.GetArrayFromImage(mask).ravel())\n",
    "        valid_labels = []\n",
    "        for label in labels:\n",
    "            if label != 0:\n",
    "                try:\n",
    "                    imageoperations.checkMask(\n",
    "                        image,\n",
    "                        mask,\n",
    "                        minimumROIDimensions=self.minimum_roi_dimensions,\n",
    "                        minimumROISize=self.minimum_roi_size,\n",
    "                        label=label,\n",
    "                    )\n",
    "                    result = label\n",
    "                except Exception as e:\n",
    "                    result = None\n",
    "                if result:\n",
    "                    valid_labels.append(result)\n",
    "        x[\"valid_labels\"] = valid_labels[:5]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CropForegroundd(transforms.MapTransform):\n",
    "    def __init__(\n",
    "        self, keys=[\"image\"], source_key=\"mask\", margin=0, k_divisible=(64, 64, 1)\n",
    "    ):\n",
    "        super().__init__(keys)\n",
    "        self.k_divisible = k_divisible\n",
    "        self.margin = margin\n",
    "        self.source_key = source_key\n",
    "\n",
    "    def __call__(self, x):\n",
    "        key = self.keys[0]\n",
    "        input_data = {\"image\": x[key], \"mask\": x[self.source_key]}\n",
    "        discs = []\n",
    "        labels = []\n",
    "        for label, disc in enumerate(x[\"valid_labels\"], start=1):\n",
    "            select_fn = lambda x: x == disc\n",
    "            crop = transforms.CropForegroundd(\n",
    "                keys=self.keys,\n",
    "                source_key=self.source_key,\n",
    "                select_fn=select_fn,\n",
    "                margin=self.margin,\n",
    "                k_divisible=self.k_divisible,\n",
    "            )(input_data)\n",
    "            discs.append(crop[\"image\"])\n",
    "            labels.append(x[str(label)])\n",
    "\n",
    "        return [{\"image\": disc, \"label\": label} for disc, label in zip(discs, labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_ = transforms.Compose(\n",
    "    [\n",
    "        CheckMaskVol(\n",
    "            keys=[\"image\", \"mask\"], minimum_roi_dimensions=3, minimum_roi_size=1000\n",
    "        ),\n",
    "        transforms.LoadImaged(\n",
    "            keys=[\"image\", \"mask\"], image_only=True, ensure_channel_first=True\n",
    "        ),\n",
    "        transforms.HistogramNormalized(keys=[\"image\"]),\n",
    "        transforms.ScaleIntensityd(keys=[\"image\"]),\n",
    "        CropForegroundd(\n",
    "            keys=[\"image\"], source_key=\"mask\", margin=0, k_divisible=(64, 64, 1)\n",
    "        ),\n",
    "        transforms.CenterSpatialCropd(keys=[\"image\"], roi_size=(64, 64, 3)),\n",
    "        # transforms.HistogramNormalized(keys=[\"image\"], num_bins=100),\n",
    "        transforms.Transposed(keys=[\"image\"], indices=(0, 3, 1, 2)),\n",
    "        transforms.SqueezeDimd(keys=[\"image\"], dim=0),\n",
    "        transforms.ToTensord(keys=[\"image\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 5\n",
    "sample = transforms_(\n",
    "    {\n",
    "        \"image\": id_labels.iloc[index][\"Image\"],\n",
    "        \"mask\": id_labels.iloc[index][\"Mask\"],\n",
    "        \"1\": id_labels.iloc[index][\"1\"],\n",
    "        \"2\": id_labels.iloc[index][\"2\"],\n",
    "        \"3\": id_labels.iloc[index][\"3\"],\n",
    "        \"4\": id_labels.iloc[index][\"4\"],\n",
    "        \"5\": id_labels.iloc[index][\"5\"],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(sample[i][\"label\"])\n",
    "    plt.imshow(sample[i][\"image\"][0, :, :], cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile bimcv_aikit/dataloaders/projects/MIDASDataLoader.py\n",
    "from monai import transforms\n",
    "from monai.data import CacheDataset, DataLoader\n",
    "from numpy import array, float32, unique\n",
    "from pandas import read_csv\n",
    "from pathlib import Path\n",
    "from radiomics import imageoperations\n",
    "from SimpleITK import GetArrayFromImage, ReadImage\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch import as_tensor, uint8\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "\n",
    "class MIDASDataLoader:\n",
    "    \"\"\"\n",
    "    A data loader for the MIDAS dataset and IVD degeneration.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        path: str,\n",
    "        sep: str = \",\",\n",
    "        test_run: bool = False,\n",
    "        partition_column: str = \"Partition\",\n",
    "        config: dict = {},\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes an instance of the MIDASDataLoader class.\n",
    "\n",
    "        Args:\n",
    "            path (str): Path to the CSV file containing the data.\n",
    "            sep (str, optional): Separator used in the CSV file. Defaults to \",\".\n",
    "            classes (list, optional): List of classes to include in the data. Defaults to [\"CN\", \"AD\"].\n",
    "            map_labels_dict (dict, optional): Dictionary mapping class names to integer labels. If provided, only the classes in the dictionary will be included in the data. Defaults to None.\n",
    "            test_run (bool, optional): If True, only a small subset of the data will be loaded for testing purposes. Defaults to False.\n",
    "            input_shape (str, optional): Spatial size of the input images. Defaults to \"(96,96,96)\".\n",
    "            partition_column (str, optional): The name of the column in the file that contains the partition. Defalts to Partition\".\n",
    "            config (dict, optional): Additional configuration options. Defaults to {}.\n",
    "        \"\"\"\n",
    "        df = read_csv(path, sep=sep)\n",
    "        n_classes = len(unique(df[\"2\"].values))\n",
    "        onehot = lambda x: one_hot(as_tensor(int(x)-1), num_classes=5).float()\n",
    "        for i in range(1, 6):\n",
    "            df[f\"onehot_{i}\"] = df[str(i)].apply(lambda x: onehot(x))\n",
    "        self.groupby = df.groupby(partition_column)\n",
    "        self._class_weights = compute_class_weight(\n",
    "            class_weight=\"balanced\",\n",
    "            classes=unique(self.groupby.get_group(\"train\")[\"2\"].values),\n",
    "            y=self.groupby.get_group(\"train\")[\"2\"].values,\n",
    "        )\n",
    "        self.transforms = transforms.Compose([\n",
    "            CheckMaskVol(keys=[\"image\", \"mask\"], minimum_roi_dimensions=3, minimum_roi_size=1000),\n",
    "            transforms.LoadImaged(keys=[\"image\", \"mask\"], image_only=True, ensure_channel_first=True),\n",
    "            transforms.HistogramNormalized(keys=[\"image\"]),\n",
    "            transforms.ScaleIntensityd(keys=[\"image\"]),\n",
    "            CropForegroundd(keys=[\"image\"], source_key=\"mask\", margin=0, k_divisible=(64, 64, 1)),\n",
    "            transforms.CenterSpatialCropd(keys=[\"image\"], roi_size=(64, 64, 3)),\n",
    "            # transforms.HistogramNormalized(keys=[\"image\"], num_bins=100),\n",
    "            transforms.Transposed(keys=[\"image\"], indices=(0, 3, 1, 2)),\n",
    "            transforms.SqueezeDimd(keys=[\"image\"], dim=0),\n",
    "            transforms.ToTensord(keys=[\"image\"]),\n",
    "        ])\n",
    "        self.test_run = test_run\n",
    "        self.config_args = config\n",
    "\n",
    "    def __call__(self, partition: str):\n",
    "        \"\"\"\n",
    "        Returns a DataLoader object for the specified partition.\n",
    "\n",
    "        Args:\n",
    "            partition (str): The partition to load data for (e.g. \"train\", \"val\", or \"test\").\n",
    "\n",
    "        Returns:\n",
    "            DataLoader: A PyTorch DataLoader object containing the specified partition's data.\n",
    "        \"\"\"\n",
    "        image_paths = self.groupby.get_group(partition)[\"Image\"].values\n",
    "        mask_paths = self.groupby.get_group(partition)[\"Mask\"].values\n",
    "        labels_disc_1 = self.groupby.get_group(partition)[\"onehot_1\"].values\n",
    "        labels_disc_2 = self.groupby.get_group(partition)[\"onehot_2\"].values\n",
    "        labels_disc_3 = self.groupby.get_group(partition)[\"onehot_3\"].values\n",
    "        labels_disc_4 = self.groupby.get_group(partition)[\"onehot_4\"].values\n",
    "        labels_disc_5 = self.groupby.get_group(partition)[\"onehot_5\"].values\n",
    "        data = [\n",
    "            {\"image\": img_path, \"mask\": mask_path, \"1\": label_disc_1, \"2\": label_disc_2, \"3\": label_disc_3, \"4\": label_disc_4, \"5\": label_disc_5, \"label\": label_disc_2,}\n",
    "            for img_path, mask_path, label_disc_1, label_disc_2, label_disc_3, label_disc_4, label_disc_5 in zip(image_paths, mask_paths, labels_disc_1, labels_disc_2, labels_disc_3, labels_disc_4, labels_disc_5)\n",
    "        ]\n",
    "        if self.test_run:\n",
    "            data = data[:16]\n",
    "        dataset = CacheDataset(data=data, transform=self.transforms, num_workers=7)\n",
    "        return DataLoader(dataset, **self.config_args)\n",
    "\n",
    "    @property\n",
    "    def class_weights(self):\n",
    "        \"\"\"\n",
    "        Returns the class weights for the dataset.\n",
    "        \"\"\"\n",
    "        return self._class_weights\n",
    "\n",
    "class CheckMaskVol(transforms.MapTransform):\n",
    "    def __init__(self, keys = [\"image\", \"mask\"], minimum_roi_dimensions: int = 3, minimum_roi_size: int = 1000):\n",
    "        super().__init__(keys)\n",
    "        self.minimum_roi_dimensions = minimum_roi_dimensions\n",
    "        self.minimum_roi_size = minimum_roi_size\n",
    "\n",
    "    def __call__(self, x):\n",
    "        image = ReadImage(x[self.keys[0]])\n",
    "        mask = ReadImage(x[self.keys[1]])\n",
    "        labels = unique(GetArrayFromImage(mask).ravel())\n",
    "        valid_labels = []\n",
    "        for label in labels:\n",
    "            if label != 0:\n",
    "                try:\n",
    "                    imageoperations.checkMask(image, mask, minimumROIDimensions=self.minimum_roi_dimensions, minimumROISize=self.minimum_roi_size, label=label)\n",
    "                    result = label\n",
    "                except Exception as e:\n",
    "                    result = None\n",
    "                if result:\n",
    "                    valid_labels.append(result)\n",
    "        x[\"valid_labels\"] = valid_labels[:5]\n",
    "        return x\n",
    "\n",
    "class CropForegroundd(transforms.MapTransform):\n",
    "    def __init__(self, keys = [\"image\"], source_key = \"mask\", margin=0, k_divisible=(64, 64, 1)):\n",
    "        super().__init__(keys)\n",
    "        self.k_divisible = k_divisible\n",
    "        self.margin = margin\n",
    "        self.source_key = source_key\n",
    "\n",
    "    def __call__(self, x):\n",
    "        key = self.keys[0]\n",
    "        input_data = {\"image\": x[key], \"mask\": x[self.source_key]}\n",
    "        discs = []\n",
    "        labels = []\n",
    "        for label, disc in enumerate(x[\"valid_labels\"], start=1):\n",
    "            select_fn = lambda x: x == disc\n",
    "            crop = transforms.CropForegroundd(keys=self.keys, \n",
    "                                              source_key=self.source_key, \n",
    "                                              select_fn=select_fn, \n",
    "                                              margin=self.margin, \n",
    "                                              k_divisible=self.k_divisible)(input_data)\n",
    "            discs.append(crop[\"image\"])\n",
    "            labels.append(x[str(label)])\n",
    "        \n",
    "        return [{\"image\": disc, \"label\": label} for disc, label in zip(discs, labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = MIDASDataLoader(\n",
    "    root_dir.joinpath(\"data\", \"filtered_midas900_t2w_partition.csv\"),\n",
    "    test_run=True,\n",
    "    config={\"batch_size\": 32, \"shuffle\": True, \"num_workers\": 7},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../src/config.json\n",
    "{\n",
    "    \"name\": \"all_discs/EfficientNetBN\",\n",
    "    \"description\": \"\",\n",
    "    \"task\": \"classification\",\n",
    "    \"n_gpu\": 1,\n",
    "    \"seed\": 42,\n",
    "    \"arch\": {\n",
    "        \"module\": \"monai.networks.nets\",\n",
    "        \"type\": \"EfficientNetBN\",\n",
    "        \"args\": {\n",
    "            \"model_name\": \"efficientnet-b7\",\n",
    "            \"spatial_dims\": 2,\n",
    "            \"in_channels\": 3,\n",
    "            \"num_classes\": 5,\n",
    "            \"pretrained\": false,\n",
    "            \"progress\": false\n",
    "        }\n",
    "    },\n",
    "    \"data_loader\": {\n",
    "        \"module\": \"bimcv_aikit.dataloaders\",\n",
    "        \"type\": \"MIDASDataLoader\",\n",
    "        \"partitions\": {\n",
    "            \"train\": \"train\",\n",
    "            \"val\": \"val\",\n",
    "            \"test\": \"test\"\n",
    "        },\n",
    "        \"args\": {\n",
    "            \"path\": \"../data/filtered_midas900_t2w_partition.csv\",\n",
    "            \"test_run\": false,\n",
    "            \"config\": {\n",
    "                \"batch_size\": 64,\n",
    "                \"drop_last\": true,\n",
    "                \"shuffle\": true\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"Adadelta\",\n",
    "        \"args\": {\n",
    "            \"lr\": 1.0,\n",
    "            \"rho\": 0.95,\n",
    "            \"eps\": 1e-07\n",
    "        }\n",
    "    },\n",
    "    \"loss\": {\n",
    "        \"module\": \"torch.nn\",\n",
    "        \"type\": \"CrossEntropyLoss\",\n",
    "        \"args\": {}\n",
    "    },\n",
    "    \"metrics\": {\n",
    "        \"accuracy\": {\n",
    "            \"module\": \"torchmetrics.functional.classification\",\n",
    "            \"type\": \"accuracy\",\n",
    "            \"args\": {\n",
    "                \"task\": \"multiclass\",\n",
    "                \"average\": \"weighted\",\n",
    "                \"num_classes\": 5\n",
    "            }\n",
    "        },\n",
    "        \"f1\": {\n",
    "            \"module\": \"torchmetrics.functional\",\n",
    "            \"type\": \"f1_score\",\n",
    "            \"args\": {\n",
    "                \"task\": \"multiclass\",\n",
    "                \"average\": \"weighted\",\n",
    "                \"num_classes\": 5\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"trainer\": {\n",
    "        \"type\": \"ClassificationTrainer\",\n",
    "        \"epochs\": 100,\n",
    "        \"save_dir\": \"../logs/\",\n",
    "        \"save_period\": 33,\n",
    "        \"verbosity\": 2,\n",
    "        \"monitor\": \"min val_loss\",\n",
    "        \"early_stop\": 100,\n",
    "        \"tensorboard\": true\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bimcv_train -c ../src/config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
