{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import SimpleITK as sitk\n",
    "from tqdm import tqdm\n",
    "\n",
    "from radiomics import imageoperations\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"DeJavu Serif\"\n",
    "plt.rcParams[\"font.serif\"] = [\"Times New Roman\"]\n",
    "\n",
    "colors = [\"#663171\", \"#ea7428\", \"#0c7156\", \"#cf3a36\", \"#e2998a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = pathlib.Path(\"..\").resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataframe_from_csv(rater: str = \"900\", from_image: str = \"t2w\") -> pd.DataFrame:\n",
    "    labels_df = pd.read_csv(root_dir.joinpath(\"data\", f\"midasdisclabels{rater}.csv\"), sep=\",\")\n",
    "    labels_df.dropna(inplace=True)\n",
    "    labels_df.rename(columns={\"subject_ID\": \"Subject_XNAT\", \"ID\": \"Session_XNAT\"}, inplace=True)\n",
    "\n",
    "    midas_img_relation = pd.read_csv(root_dir.joinpath(\"data\", \"filtered_midas900_t2w.csv\"), sep=\",\")\n",
    "    midas_img_relation[\"Subject_MIDS\"] = midas_img_relation[\"Image\"].map(lambda x: x.split(\"/\")[8])\n",
    "    midas_img_relation[\"Session_MIDS\"] = midas_img_relation[\"Image\"].map(lambda x: x.split(\"/\")[9])\n",
    "    midas_img_relation[\"Subject_XNAT\"] = midas_img_relation[\"Subject_MIDS\"].map(lambda x: f\"ceibcs_S{int(x.split('sub-S')[1])}\")\n",
    "    midas_img_relation[\"Session_XNAT\"] = midas_img_relation[\"Session_MIDS\"].map(lambda x: f\"ceibcs_E{int(x.split('ses-E')[1])}\")\n",
    "\n",
    "    id_labels = labels_df.merge(midas_img_relation, on=[\"Subject_XNAT\", \"Session_XNAT\"])\n",
    "    id_labels.rename(\n",
    "        columns={\n",
    "            \"L5-S\": \"1\",\n",
    "            \"L4-L5\": \"2\",\n",
    "            \"L3-L4\": \"3\",\n",
    "            \"L2-L3\": \"4\",\n",
    "            \"L1-L2\": \"5\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    radiomic_features = pd.read_csv(root_dir.joinpath(\"data\", f\"filtered_midas900_{from_image}_radiomics.csv\"), sep=\",\")\n",
    "    radiomic_features.rename(columns={\"Unnamed: 0\": \"ID\"}, inplace=True)\n",
    "\n",
    "    return id_labels.merge(radiomic_features, on=\"ID\")\n",
    "\n",
    "def get_labels_and_features(rater: str = \"900\", label: int = 1, from_image: str = \"t2w\") -> tuple:\n",
    "    \"\"\"\n",
    "    Reads a CSV file from the given label and returns the labels and features as separate dataframes.\n",
    "\n",
    "    :param rater: The rater identifier. Default is \"900\".\n",
    "    :type rater: str\n",
    "    :param label: A number from 1 to 5 indicating the disc of interest. Default is 1.\n",
    "    :type label: bool\n",
    "    :return: A tuple containing the labels and features.\n",
    "    :rtype: tuple\n",
    "    \"\"\"\n",
    "\n",
    "    data = build_dataframe_from_csv(rater=rater, from_image=from_image)\n",
    "\n",
    "    data = data.rename(columns={str(label): f\"label{label}\", \"ID\": f\"label{label}ID\"})\n",
    "    columns_mask = data.columns.str.contains(f\"label{label}\") & ~data.columns.str.contains(\"Configuration\")\n",
    "    data = data.loc[:, columns_mask]\n",
    "    data = data.rename(columns={f\"label{label}\": \"label\", f\"label{label}ID\": \"ID\"})\n",
    "\n",
    "    label_data = data.dropna(axis=0, how=\"any\")\n",
    "    label_data = label_data.loc[label_data[\"label\"] != 0]\n",
    "    label_data[\"ID\"] = label_data[\"ID\"].map(lambda x: x + str(label))\n",
    "    label_data = label_data.set_index(\"ID\")\n",
    "    labels = label_data[\"label\"]\n",
    "    features = label_data[label_data.select_dtypes(include=\"number\").columns.tolist()].drop(columns=\"label\")\n",
    "    return labels, features\n",
    "\n",
    "\n",
    "def get_labels_and_features_all_discs(rater: str = \"900\", verbose: bool = False, from_image: str = \"t1w_t2w\") -> tuple:\n",
    "    \"\"\"\n",
    "    Get labels and features for all discs.\n",
    "\n",
    "    :param rater: The rater identifier. Default is \"900\".\n",
    "    :type rater: str\n",
    "    :param verbose: Whether to print additional information and plot the label distribution. Default is False.\n",
    "    :type verbose: bool\n",
    "    :return: A tuple containing the labels and features.\n",
    "    :rtype: tuple\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    for label in range(1, 6):\n",
    "        labels_i, features_i = get_labels_and_features(rater=rater, label=label, from_image=from_image)\n",
    "        labels.append(labels_i)\n",
    "        features_i = features_i.rename(columns={name: name.replace(f\"label{label}_\", \"\") for name in features_i.columns.to_list()})\n",
    "        features.append(features_i)\n",
    "    features = pd.concat(features, axis=0)\n",
    "    labels = pd.concat(labels, axis=0)\n",
    "    if verbose:\n",
    "        print(f\"Labels shape: {labels.shape}, Features shape: {features.shape}\")\n",
    "        labels.plot(kind=\"hist\", xticks=[1, 2, 3, 4, 5], title=\"Label distribution\")\n",
    "        plt.show()\n",
    "    return labels, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "\n",
    "class VarianceFeatureReduction(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    VarianceFeatureReduction is a transformer that reduces the feature space by removing features with low variance.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    threshold : float, optional (default=0.05)\n",
    "        The threshold below which features will be removed.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, threshold=0.05):\n",
    "        self.threshold = threshold\n",
    "        self.selector = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit the VarianceFeatureReduction transformer to the input data.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The input data.\n",
    "        y : array-like, shape (n_samples,), optional (default=None)\n",
    "            The target values.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        self.selector = VarianceThreshold(threshold=self.threshold)\n",
    "        self.selector.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Transform the input data by removing features with low variance.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The input data.\n",
    "        y : array-like, shape (n_samples,), optional (default=None)\n",
    "            The target values.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        X_ : array-like, shape (n_samples, n_selected_features)\n",
    "            The transformed data with low variance features removed.\n",
    "        \"\"\"\n",
    "        X_ = X.copy()\n",
    "        X_ = X_.loc[:, self.selector.get_support()]\n",
    "        return X_\n",
    "\n",
    "\n",
    "class CorrelationFeatureReduction(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    A transformer class for reducing features based on correlation.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    threshold : float, optional (default=0.8)\n",
    "        The threshold above which features will be removed.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, threshold=0.8):\n",
    "        self.threshold = threshold\n",
    "        self.corr_matrix_var = None\n",
    "        self.to_keep = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit the transformer to the input data.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : pandas DataFrame\n",
    "            The input data.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        self : CorrelationFeatureReduction\n",
    "            The fitted transformer object.\n",
    "\n",
    "        \"\"\"\n",
    "        self.corr_matrix_var = X.corr(method=\"spearman\").abs()  # absolute correlation matrix\n",
    "\n",
    "        # Initialize the flag vector with True values\n",
    "        self.to_keep = np.full((self.corr_matrix_var.shape[1]), True, dtype=bool)\n",
    "\n",
    "        for i in range(self.corr_matrix_var.shape[1]):\n",
    "            for j in range(i + 1, self.corr_matrix_var.shape[1]):\n",
    "                if self.to_keep[i] and self.corr_matrix_var.iloc[i, j] >= self.threshold:\n",
    "                    if self.to_keep[j]:\n",
    "                        self.to_keep[j] = False\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Transform the input data by removing highly correlated features.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : pandas DataFrame\n",
    "            The input data.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        X_ : pandas DataFrame\n",
    "            The transformed data with highly correlated features removed.\n",
    "\n",
    "        \"\"\"\n",
    "        X_ = X.copy()\n",
    "        X_ = X_.iloc[:, self.to_keep]\n",
    "        return X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def test_multiple_models(features, labels):\n",
    "    # Define classifiers to test\n",
    "    classifiers = {\n",
    "        \"Random Forest\": RandomForestClassifier(),\n",
    "        \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "        \"SVM\": SVC(),\n",
    "        \"Logistic Regression\": LogisticRegression(),\n",
    "        \"Stochastic Gradient Descent\": SGDClassifier(),\n",
    "        \"Naive Bayes\": GaussianNB(),\n",
    "        \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "        \"Multilayer Perceptron\": MLPClassifier(),\n",
    "        \"AdaBoost\": AdaBoostClassifier(),\n",
    "        \"ExtraTrees\": ExtraTreesClassifier(),\n",
    "    }\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.25, random_state=0, stratify=labels)\n",
    "\n",
    "    # Test each classifier\n",
    "    f1_scores = {}\n",
    "    for name, clf in classifiers.items():\n",
    "        pipeline = Pipeline(\n",
    "            [\n",
    "                (\"variancethreshold\", VarianceFeatureReduction(threshold=0.05)),\n",
    "                (\"correlationreduction\", CorrelationFeatureReduction()),\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"classifier\", clf),\n",
    "            ]\n",
    "        )\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        f1_scores[name] = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "    # Select the classifier with the highest F1 score\n",
    "    best_classifier = max(f1_scores, key=f1_scores.get)  # type: ignore\n",
    "    print(\"Best classifier:\", best_classifier)\n",
    "    print(\"F1 score:\", f1_scores[best_classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "\n",
    "def cv(clf, features, labels):\n",
    "    # Create a stratified 5-fold cross-validation object\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    pipeline_clf = Pipeline(\n",
    "        [\n",
    "            (\"variancethreshold\", VarianceFeatureReduction(threshold=0.05)),\n",
    "            (\"correlationreduction\", CorrelationFeatureReduction()),\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"classifier\", clf),\n",
    "        ]\n",
    "    )\n",
    "    scores = cross_val_score(pipeline_clf, features, labels, cv=skf, scoring=\"f1_weighted\")\n",
    "    print(f\"Cross Validation F1 Score: {scores.mean():0.4f} +/- {scores.std():0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "def imbalanced_learning_suite(features, labels):\n",
    "    # Define classifiers to test\n",
    "    classifiers = {\n",
    "        \"Balanced Bagging Classifier\": BalancedBaggingClassifier(sampler=RandomUnderSampler()),\n",
    "        \"Balanced RandomForest Classifier\": BalancedRandomForestClassifier(),\n",
    "        \"RUS Boost Classifier\": RUSBoostClassifier(),\n",
    "        \"Easy Ensemble Classifier\": EasyEnsembleClassifier(),\n",
    "    }\n",
    "\n",
    "    # Create a stratified 5-fold cross-validation object\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    for name, clf in classifiers.items():\n",
    "        pipeline_clf = Pipeline(\n",
    "            [\n",
    "                (\"variancethreshold\", VarianceFeatureReduction(threshold=0.05)),\n",
    "                (\"correlationreduction\", CorrelationFeatureReduction()),\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"classifier\", clf),\n",
    "            ]\n",
    "        )\n",
    "        scores = cross_val_score(pipeline_clf, features, labels, cv=skf, scoring=\"f1_weighted\")\n",
    "        print(f\"{name}: {scores.mean():0.2f} f1 with a standard deviation of {scores.std():0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yellowbrick.classifier as viz\n",
    "\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report\n",
    "from yellowbrick.style import set_palette\n",
    "\n",
    "set_palette(colors)\n",
    "\n",
    "\n",
    "def visual_metrics(clf, features, labels, classes=[\"1\", \"2\", \"3\", \"4\", \"5\"]):\n",
    "    labels_ = labels.copy()\n",
    "    if min(labels_) != 0:\n",
    "        labels_ = labels_ - min(labels_)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels_, test_size=0.25, random_state=0, stratify=labels_)\n",
    "\n",
    "    _, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    labels.plot(kind=\"hist\", title=\"Pfirmann grade distribution\", ax=axes[0], xticks=[1, 2, 3, 4, 5], align=\"mid\")\n",
    "\n",
    "    pipeline_clf = Pipeline(\n",
    "        [\n",
    "            (\"variancethreshold\", VarianceFeatureReduction(threshold=0.05)),\n",
    "            (\"correlationreduction\", CorrelationFeatureReduction()),\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"classifier\", clf),\n",
    "        ]\n",
    "    )\n",
    "    pipeline_clf.fit(X_train, y_train)\n",
    "    axes[1].set_title(\"Classification Report\")\n",
    "    axes[1].set_ylabel(\"Class\")\n",
    "    visualizer_class = viz.ClassificationReport(pipeline_clf, classes=classes[::-1], support=True, ax=axes[1], cmap=\"Blues\")\n",
    "    visualizer_class.score(X_test, y_test)\n",
    "\n",
    "    axes[2].set_title(\"Classification Prediction Error\")\n",
    "    axes[2].set_xlabel(\"Class\")\n",
    "    axes[2].set_ylabel(\"Number of Predictions\")\n",
    "    visualizer_pred = viz.ClassPredictionError(pipeline_clf, classes=classes, ax=axes[2])\n",
    "    visualizer_pred.score(X_test, y_test)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    predictions = pipeline_clf.predict(X_test)\n",
    "    print(f\"Accuracy within one grade: {accuracy_within_one(y_test, predictions):0.2f}\")\n",
    "    print(f\"Balanced accuracy: {balanced_accuracy_score(y_test, predictions):0.2f}\")\n",
    "    print(classification_report(y_test, predictions, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "def random_search(clf, distribution, features, labels):\n",
    "    pipeline_clf = Pipeline(\n",
    "        [\n",
    "            (\"variancethreshold\", VarianceFeatureReduction(threshold=0.05)),\n",
    "            (\"correlationreduction\", CorrelationFeatureReduction()),\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"classifier\", clf),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    rs_clf = RandomizedSearchCV(pipeline_clf, distribution, cv=skf, scoring=\"f1_weighted\", n_iter=10, random_state=0)\n",
    "    search = rs_clf.fit(features, labels)\n",
    "\n",
    "    print(f\"Best parameter (CV score={search.best_score_:0.3f}): {search.best_params_}\")\n",
    "    return {key.replace(\"classifier__\", \"\"): value for key, value in search.best_params_.items() if key.startswith(\"classifier__\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkMaskVol(image, mask, label):\n",
    "    try:\n",
    "        imageoperations.checkMask(image, mask, minimumROIDimensions=3, minimumROISize=1000, label=label)\n",
    "        result = label\n",
    "    except Exception as e:\n",
    "        result = None\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_within_one(labels, predictions):\n",
    "    # Calculate the absolute difference between labels and predictions\n",
    "    diff = abs(labels - predictions)\n",
    "    # Count the number of differences that are less than or equal to one\n",
    "    correct_predictions = sum(diff <= 1)\n",
    "    # Calculate the accuracy\n",
    "    accuracy = correct_predictions / len(labels)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = build_dataframe_from_csv(rater=\"JDCarlos\", from_image=\"t2w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "discs = {\n",
    "    \"1\": \"L5-S\",\n",
    "    \"2\":\"L4-L5\",\n",
    "    \"3\":\"L3-L4\",\n",
    "    \"4\":\"L2-L3\",\n",
    "    \"5\":\"L1-L2\",\n",
    "}\n",
    "for i in range(1, 6):\n",
    "    s  = df[f\"{i}\"].value_counts()\n",
    "    s.name = discs[f\"{i}\"]\n",
    "    a.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(a).T\n",
    "\n",
    "fig = px.bar(df1, title=\"Pfirrmann Grade Distribution\", color_discrete_sequence=colors)  # replace 0 with your column name if needed\n",
    "total_count = df1.sum(axis=1)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df1.index,\n",
    "    y=total_count,\n",
    "    mode='text',\n",
    "    text=total_count,\n",
    "    textposition='top center',\n",
    "    showlegend=False\n",
    "))\n",
    "fig.update_traces(textfont_size=12)\n",
    "fig.update_xaxes(title_text='Pfirrmann Grade')\n",
    "fig.update_yaxes(title_text='Frequency', showgrid=True, gridcolor='rgba(184, 184, 184, 0.3)')\n",
    "fig.update_layout(\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    legend_title_text= \"Intervertebral Disc\",\n",
    "    grid_rows=1,\n",
    ")\n",
    "fig.show()\n",
    "# pio.write_image(fig, root_dir.joinpath(\"figures\", \"pfirrmann_grade_distribution.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai.transforms as transforms\n",
    "import torch\n",
    "\n",
    "class CheckMaskVol(transforms.MapTransform):\n",
    "    def __init__(self, keys = [\"image\", \"mask\"], minimum_roi_dimensions: int = 3, minimum_roi_size: int = 1000):\n",
    "        super().__init__(keys)\n",
    "        self.minimum_roi_dimensions = minimum_roi_dimensions\n",
    "        self.minimum_roi_size = minimum_roi_size\n",
    "\n",
    "    def __call__(self, x):\n",
    "        image = sitk.ReadImage(x[self.keys[0]])\n",
    "        mask = sitk.ReadImage(x[self.keys[1]])\n",
    "        labels = np.unique(sitk.GetArrayFromImage(mask).ravel())\n",
    "        valid_labels = []\n",
    "        for label in labels:\n",
    "            if label != 0:\n",
    "                try:\n",
    "                    imageoperations.checkMask(image, mask, minimumROIDimensions=self.minimum_roi_dimensions, minimumROISize=self.minimum_roi_size, label=label)\n",
    "                    result = label\n",
    "                except Exception as e:\n",
    "                    result = None\n",
    "                if result:\n",
    "                    valid_labels.append(result)\n",
    "        x[\"valid_labels\"] = valid_labels[:5]\n",
    "        return x\n",
    "    \n",
    "class CropForegroundd(transforms.MapTransform):\n",
    "    def __init__(self, keys = [\"image\"], source_key = \"mask\", margin=0, k_divisible=(64, 64, 1)):\n",
    "        super().__init__(keys)\n",
    "        self.k_divisible = k_divisible\n",
    "        self.margin = margin\n",
    "        self.source_key = source_key\n",
    "\n",
    "    def __call__(self, x):\n",
    "        key = self.keys[0]\n",
    "        bool_mask = torch.where(x[self.source_key] == x[\"valid_labels\"][0], x[self.source_key], 0)\n",
    "        for label in x[\"valid_labels\"][1:]:\n",
    "            bool_mask += torch.where(x[self.source_key] == label, x[self.source_key], 0)\n",
    "        input_data = {\"image\": x[key] * bool_mask, \"mask\": x[self.source_key]}\n",
    "        discs = []\n",
    "        labels = []\n",
    "        for label, disc in enumerate(x[\"valid_labels\"], start=1):\n",
    "            select_fn = lambda x: x == disc\n",
    "            crop = transforms.CropForegroundd(keys=self.keys, \n",
    "                                              source_key=self.source_key, \n",
    "                                              select_fn=select_fn, \n",
    "                                              margin=self.margin, \n",
    "                                              k_divisible=self.k_divisible)(input_data)\n",
    "            crop2 = transforms.CenterSpatialCropd(keys=[\"image\"], roi_size=(-1, -1, 1))(crop)\n",
    "            discs.append(crop2[\"image\"])\n",
    "            labels.append(x[str(label)])\n",
    "        return [{\"image\": disc, \"label\": label} for disc, label in zip(discs, labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_ = transforms.Compose([\n",
    "    CheckMaskVol(keys=[\"image\", \"mask\"], minimum_roi_dimensions=3, minimum_roi_size=1000),\n",
    "    transforms.LoadImaged(keys=[\"image\", \"mask\"], image_only=True, ensure_channel_first=True),\n",
    "    CropForegroundd(keys=[\"image\"], source_key=\"mask\", margin=0, k_divisible=(1, 1, 1)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\"Discs\": [], \"Pfirmann\": [], \"Array\": []}\n",
    "for _, row in tqdm(df.iterrows()):\n",
    "    data = {\"image\": row[\"Image\"], \n",
    "            \"mask\": row[\"Mask\"], \n",
    "            \"1\": row[\"1\"],\n",
    "            \"2\": row[\"2\"],\n",
    "            \"3\": row[\"3\"],\n",
    "            \"4\": row[\"4\"],\n",
    "            \"5\": row[\"5\"],}\n",
    "    result_row=transforms_(data)\n",
    "    for idx, result in enumerate(result_row, start=1):\n",
    "        results[\"Discs\"].append(idx)\n",
    "        results[\"Pfirmann\"].append(result[\"label\"])\n",
    "        results[\"Array\"].append(result[\"image\"].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms_df = pd.DataFrame(results)\n",
    "histograms_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process = histograms_df.copy()\n",
    "process[\"Normalized Array\"] = process[\"Array\"].map(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "process[\"Histogram\"] = process[\"Normalized Array\"].map(lambda x: np.histogram(x, bins=10)[0])\n",
    "grouped_by_disc = process.groupby(\"Pfirmann\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = np.arange(0, 1.01, 1/10)\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(4, -1, -1):\n",
    "    plt.bar(x=x_[:-1], height=grouped_by_disc[\"Histogram\"].mean().iloc[i], width=np.diff(x_), label=str(i+1))\n",
    "plt.legend()\n",
    "# plt.ylim(0, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    " \n",
    "# Plotting\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    " \n",
    "# X, Y positions for the bars\n",
    "x_positions = x_[:-1]\n",
    "y_positions = [0, 1, 2, 3, 4]  # Different datasets on different y-positions\n",
    " \n",
    "# Width of each bar and yz-space between bars\n",
    "width = np.diff(x_)\n",
    "y_space = 0.8\n",
    " \n",
    "# Adding the histograms to the plot\n",
    "for i, hist in enumerate(grouped_by_disc[\"Histogram\"].mean()):\n",
    "    ax.bar(x_positions, hist, zs=y_positions[i], zdir='y', width=width, align='center', alpha=0.7)\n",
    " \n",
    "ax.set_xlabel('X-axis (Value)')\n",
    "# ax.set_ylabel('Y-axis (Dataset)')\n",
    "ax.set_zlabel('Z-axis (Frequency)')\n",
    " \n",
    "# Setting the y-ticks to correspond to different datasets\n",
    "ax.set_yticks(y_positions)\n",
    "ax.set_yticklabels(['Pfirrmann 1', 'Pfirrmann 2', 'Pfirrmann 3', 'Pfirrmann 4', 'Pfirrmann 5'])\n",
    " \n",
    "plt.title('3D Histograms')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Near-zero variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Feature reduction based on variance thresholding (remove features with variance smaller than 0.05)\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Initialize selector based on VarianceThreshold\n",
    "selector = VarianceThreshold(threshold=0.05)\n",
    "\n",
    "#  Estimate variances and reduce features\n",
    "labels, radiomic_features = get_labels_and_features_all_discs(rater=\"JDCarlos\")\n",
    "selector.fit_transform(radiomic_features)\n",
    "\n",
    "# Get the selected feature labels and reduce the Radiomic_Feature dataframe\n",
    "radiomic_features_var = radiomic_features.loc[:, selector.get_support()]\n",
    "\n",
    "# Display the number of features removed\n",
    "print(f\"{np.count_nonzero(~selector.get_support())}/{radiomic_features.shape[1]} features were removed due to near-zero variance.\")\n",
    "\n",
    "del selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix_var = radiomic_features_var.corr(method=\"spearman\").abs()  # absolute correlation matrix\n",
    "\n",
    "# Initialize the flag vector with True values\n",
    "to_keep = np.full((corr_matrix_var.shape[1]), True, dtype=bool)\n",
    "\n",
    "for i in range(corr_matrix_var.shape[1]):\n",
    "    for j in range(i + 1, corr_matrix_var.shape[1]):\n",
    "        if to_keep[i] and corr_matrix_var.iloc[i, j] >= 0.8:\n",
    "            if to_keep[j]:\n",
    "                to_keep[j] = False\n",
    "\n",
    "# Retain features that are not higly correlated\n",
    "radiomic_features_corr = radiomic_features_var.iloc[:, to_keep]\n",
    "\n",
    "print(\n",
    "    f\"{np.count_nonzero(~to_keep)}/{radiomic_features_var.shape[1]} features were removed due to high correlation. {radiomic_features_corr.shape[1]} features remaining.\"\n",
    ")\n",
    "\n",
    "del to_keep, i, j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Calculate the correlation matrix of the original feature set\n",
    "corr_matrix = radiomic_features.corr(method=\"spearman\")\n",
    "# Display the correlation matrix\n",
    "plt.figure(figsize=(8, 6.5))\n",
    "sns.heatmap(corr_matrix, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "plt.title(\"Correlation of Radiomic features\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate the correlation matrix of the reduced feature set\n",
    "corr_matrix_red = radiomic_features_corr.corr(method=\"spearman\")\n",
    "# Display the correlation matrix\n",
    "plt.figure(figsize=(8, 6.5))\n",
    "sns.heatmap(corr_matrix_red, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "plt.title(\"Correlation of reduced radiomic features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from scipy.stats import zscore\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "\n",
    "radiomic_features_clus = copy.deepcopy(radiomic_features_corr)\n",
    "# Normalize the data\n",
    "radiomic_features_clus = zscore(radiomic_features_clus, axis=0)\n",
    "\n",
    "# Calculate and plot the clustergram\n",
    "row_linkage = hierarchy.linkage(distance.pdist(radiomic_features_clus.to_numpy()), method=\"ward\")\n",
    "col_linkage = hierarchy.linkage(distance.pdist(radiomic_features_clus.T.to_numpy()), method=\"ward\")\n",
    "g = sns.clustermap(\n",
    "    radiomic_features_clus, row_linkage=row_linkage, col_linkage=col_linkage, method=\"ward\", vmin=-3, vmax=3, figsize=(8, 10), cmap=\"viridis\"\n",
    ")\n",
    "g.ax_cbar.set_position((0.90, 0.2, 0.03, 0.3))\n",
    "\n",
    "# Extract 5 disc degeneration clusters and append the \"Clusters\" variable to the DataFrame\n",
    "n_clusters = 5\n",
    "radiomic_features_clus[\"Clusters\"] = fcluster(row_linkage, n_clusters, criterion=\"maxclust\")\n",
    "\n",
    "# Print the cluster assignments\n",
    "print(\"Cluster Assignments:\", radiomic_features_clus[\"Clusters\"])\n",
    "\n",
    "del g, n_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Concatenate the target clinical variable to the radiomic DataFrame\n",
    "radiomic_features_clus = pd.concat([radiomic_features_clus, labels], axis=1)\n",
    "\n",
    "# Barplot clusters/grades\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.countplot(x=\"Clusters\", hue=\"label\", data=radiomic_features_clus, palette=\"coolwarm\")\n",
    "plt.title(\"Distribution of Pfirmann grade in each Cluster\")\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend(title=\"Pfirmann grade\", loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "# Perform chi-squared test\n",
    "chi2, p, _, _ = chi2_contingency(pd.crosstab(radiomic_features_clus[\"label\"], radiomic_features_clus[\"Clusters\"]))\n",
    "\n",
    "# Print the results\n",
    "print(f\"Chi-squared statistic: {chi2}\")\n",
    "print(f\"P-value: {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disc_results(clf, disc: int = 1):\n",
    "    labels, features = get_labels_and_features(rater=\"JDCarlos\", label=disc)\n",
    "    cv(clf, features, labels)\n",
    "    visual_metrics(clf, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in range(1, 6):\n",
    "    print(f\"Disc: {label}\")\n",
    "    labels, features = get_labels_and_features(rater=\"JDCarlos\", label=label)\n",
    "    test_multiple_models(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Disc 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier()\n",
    "disc_results(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disc 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier()\n",
    "disc_results(clf, disc=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disc 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier()\n",
    "disc_results(clf, disc=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disc 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier()\n",
    "disc_results(clf, disc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disc 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC()\n",
    "disc_results(clf, disc=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All discs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_discs_results(clf):\n",
    "    labels, features = get_labels_and_features_all_discs(rater=\"JDCarlos\")\n",
    "    # cv(clf, features, labels)\n",
    "    visual_metrics(clf, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, features = get_labels_and_features_all_discs(rater=\"JDCarlos\")\n",
    "test_multiple_models(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC()\n",
    "all_discs_results(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, features = get_labels_and_features_all_discs(rater=\"JDCarlos\")\n",
    "labels_ = labels.copy()\n",
    "if min(labels_) != 0:\n",
    "    labels_ = labels_ - min(labels_)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels_, test_size=0.25, random_state=0, stratify=labels_)\n",
    "\n",
    "clf = SVC()\n",
    "pipeline_clf = Pipeline(\n",
    "    [\n",
    "        (\"variancethreshold\", VarianceFeatureReduction(threshold=0.05)),\n",
    "        (\"correlationreduction\", CorrelationFeatureReduction()),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"classifier\", clf),\n",
    "    ]\n",
    ")\n",
    "pipeline_clf.fit(X_train, y_train)\n",
    "# Predict the values for the test set\n",
    "y_pred = pipeline_clf.predict(X_test)\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Convert the report to a DataFrame\n",
    "df = pd.DataFrame(report).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_int = lambda x: str(int(x)) if x > 1 else f'{x:.2f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.iloc[:5]\n",
    "df1_ = df1.copy()\n",
    "df1_[\"support\"] = 0.1\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "                   z=df1_.values.tolist(),\n",
    "                   x=df1.columns,\n",
    "                   y=[str(i) for i in range(1, 6)],\n",
    "                   colorscale=[\"#ffffff\", colors[1]],\n",
    "                   showscale=True,\n",
    "                   xgap=1,\n",
    "                   ygap=1,\n",
    "                   zmin=0,\n",
    "                   zmax=1,\n",
    "                   hoverinfo='none',\n",
    "                   hoverongaps=False,\n",
    "                   text=[[float_int(val) for val in row] for row in df1.values.tolist()],\n",
    "                   texttemplate=\"%{text}\",\n",
    "               ))\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    margin=dict(\n",
    "        pad=10\n",
    "    ),\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    "    legend_title_text= \"Intervertebral Disc\",\n",
    "    grid_rows=1,\n",
    "    title=\"Per grade classification results for the five level grading task\"\n",
    ")\n",
    "fig.update_xaxes(automargin=True,\n",
    "                 tickvals=list(range(len(df1.columns))), \n",
    "                 ticktext=[col.capitalize() for col in df1.columns],\n",
    "                 showgrid=False)\n",
    "fig.update_yaxes(automargin=True,\n",
    "                 title_text='Pfirrmann Grade',\n",
    "                 showgrid=False)\n",
    "fig.update_traces(textfont_size=16,)\n",
    "fig.show()\n",
    "# fig.write_image(root_dir.joinpath(\"figures\", \"per_grade_5_levels.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_series = pd.Series(y_pred, name=\"Predicted\")\n",
    "y_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([pred_series, y_test]).add(1).astype(int)\n",
    "df = df.T.groupby(\"Predicted\").value_counts().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(df, title=\"Class Prediction Error\", color_discrete_sequence=colors)  # replace 0 with your column name if needed\n",
    "\n",
    "total_count = df.sum(axis=1)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df.index,\n",
    "    y=total_count,\n",
    "    mode='text',\n",
    "    text=total_count,\n",
    "    textposition='top center',\n",
    "    showlegend=False\n",
    "))\n",
    "fig.update_traces(textfont_size=12)\n",
    "fig.update_xaxes(title_text='Predicted Pfirrmann Grade')\n",
    "fig.update_yaxes(title_text='Frequency', showgrid=True, gridcolor='rgba(184, 184, 184, 0.3)')\n",
    "fig.update_layout(\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    "    legend_title_text= \"True Pfirrmann Grade\",\n",
    "    grid_rows=1,\n",
    ")\n",
    "fig.show()\n",
    "# fig.write_image(root_dir.joinpath(\"figures\", \"class_prediction_error_5level.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, features = get_labels_and_features_all_discs(rater=\"JDCarlos\")\n",
    "imbalanced_learning_suite(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining classes 1 and 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disc_results_combining_1_and_2(clf, disc: int = 1):\n",
    "    labels, features = get_labels_and_features(rater=\"JDCarlos\", label=disc)\n",
    "    labels.loc[labels == 1] = 2\n",
    "    cv(clf, features, labels)\n",
    "    visual_metrics(clf, features, labels, classes=[\"1 and 2\", \"3\", \"4\", \"5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in range(1, 6):\n",
    "    print(f\"Disc: {label}\")\n",
    "    labels, features = get_labels_and_features(rater=\"JDCarlos\", label=label)\n",
    "    labels.loc[labels == 1] = 2\n",
    "    test_multiple_models(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disc 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier()\n",
    "disc_results_combining_1_and_2(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disc 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ExtraTreesClassifier()\n",
    "disc_results_combining_1_and_2(clf, disc=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disc 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ExtraTreesClassifier()\n",
    "disc_results_combining_1_and_2(clf, disc=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disc 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "disc_results_combining_1_and_2(clf, disc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disc 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier()\n",
    "disc_results_combining_1_and_2(clf, disc=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All discs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_discs_results_combining_1_and_2(clf):\n",
    "    labels, features = get_labels_and_features_all_discs(rater=\"JDCarlos\")\n",
    "    labels.loc[labels == 1] = 2\n",
    "    cv(clf, features, labels)\n",
    "    visual_metrics(clf, features, labels, classes=[\"1 and 2\", \"3\", \"4\", \"5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, features = get_labels_and_features_all_discs(rater=\"JDCarlos\")\n",
    "labels.loc[labels == 1] = 2\n",
    "test_multiple_models(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "all_discs_results_combining_1_and_2(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, features = get_labels_and_features_all_discs(rater=\"JDCarlos\")\n",
    "labels.loc[labels == 1] = 2\n",
    "imbalanced_learning_suite(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, features = get_labels_and_features_all_discs(rater=\"JDCarlos\")\n",
    "labels_ = labels.copy()\n",
    "labels_.loc[labels_ == 1] = 2\n",
    "if min(labels_) != 0:\n",
    "    labels_ = labels_ - min(labels_)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels_, test_size=0.25, random_state=0, stratify=labels_)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "pipeline_clf = Pipeline(\n",
    "    [\n",
    "        (\"variancethreshold\", VarianceFeatureReduction(threshold=0.05)),\n",
    "        (\"correlationreduction\", CorrelationFeatureReduction()),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"classifier\", clf),\n",
    "    ]\n",
    ")\n",
    "pipeline_clf.fit(X_train, y_train)\n",
    "# Predict the values for the test set\n",
    "y_pred = pipeline_clf.predict(X_test)\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Convert the report to a DataFrame\n",
    "df = pd.DataFrame(report).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_ = df.iloc[:4].copy()\n",
    "df1_[\"support\"] = 0.1\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "                   z=df1_.values.tolist(),\n",
    "                   x=df1.columns,\n",
    "                   y=[\"1 and 2\", \"3\", \"4\", \"5\"],\n",
    "                   colorscale=[\"#ffffff\", colors[4]],\n",
    "                   zmin=0,\n",
    "                   zmax=1,\n",
    "                   showscale=True,\n",
    "                   xgap=1,\n",
    "                   ygap=1,\n",
    "                   text=[[float_int(val) for val in row] for row in df.iloc[:4].values.tolist()],\n",
    "                   texttemplate=\"%{text}\",\n",
    "               ))\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    margin=dict(\n",
    "        pad=10  # padding\n",
    "    ),\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    "    legend_title_text= \"Intervertebral Disc\",\n",
    "    grid_rows=1,\n",
    "    title=\"Per grade classification results for the four level grading task\"\n",
    ")\n",
    "fig.update_xaxes(automargin=True,\n",
    "                 tickvals=list(range(len(df1.columns))), \n",
    "                 ticktext=[col.capitalize() for col in df1_.columns],\n",
    "                 showgrid=False)\n",
    "fig.update_yaxes(automargin=True,\n",
    "                 title_text='Pfirrmann Grade',\n",
    "                 showgrid=False)\n",
    "fig.update_traces(textfont_size=16,)\n",
    "fig.show()\n",
    "# fig.write_image(root_dir.joinpath(\"figures\", \"per_grade_4_levels.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_series = pd.Series(y_pred, name=\"Predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([pred_series, y_test]).add(2).astype(int)\n",
    "df = df.T.groupby(\"Predicted\").value_counts().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(df, title=\"Class Prediction Error\", color_discrete_sequence=colors)  # replace 0 with your column name if needed\n",
    "\n",
    "for name, trace in zip([\"1 and 2\", \"3\", \"4\", \"5\"], fig.data):\n",
    "    trace.name = name\n",
    "\n",
    "total_count = df.sum(axis=1)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df.index,\n",
    "    y=total_count,\n",
    "    mode='text',\n",
    "    text=total_count,\n",
    "    textposition='top center',\n",
    "    showlegend=False\n",
    "))\n",
    "fig.update_traces(textfont_size=12)\n",
    "fig.update_xaxes(title_text='Predicted Pfirrmann Grade',\n",
    "                 tickvals=list(range(2, 6)), \n",
    "                 ticktext=[\"1 and 2\", \"3\", \"4\", \"5\"],)\n",
    "fig.update_yaxes(title_text='Frequency', showgrid=True, gridcolor='rgba(184, 184, 184, 0.3)')\n",
    "fig.update_layout(\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    "    legend_title_text= \"True Pfirrmann Grade\",\n",
    "    grid_rows=1,\n",
    ")\n",
    "fig.show()\n",
    "# fig.write_image(root_dir.joinpath(\"figures\", \"class_prediction_error_4level.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radiomics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
