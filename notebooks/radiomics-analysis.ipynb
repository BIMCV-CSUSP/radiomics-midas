{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "\n",
    "root_dir = pathlib.Path(\"..\").resolve()\n",
    "\n",
    "sys.path.append(str(root_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import SimpleITK as sitk\n",
    "from irrCAC.raw import CAC\n",
    "from radiomics import imageoperations\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.ml.transforms import CorrelationFeatureReduction, ICCFeatureReduction, mRMRFeatureReduction, VarianceFeatureReduction\n",
    "from src.ml.utils import build_dataframe_from_csv, get_labels_and_features, get_labels_and_features_all_discs\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"DeJavu Serif\"\n",
    "plt.rcParams[\"font.serif\"] = [\"Times New Roman\"]\n",
    "\n",
    "colors = [\"#663171\", \"#ea7428\", \"#0c7156\", \"#cf3a36\", \"#e2998a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_img_relation_path = root_dir.joinpath(\"data\", \"filtered_midas900_t2w.csv\")\n",
    "label_path = lambda rater: root_dir.joinpath(\"data\", \"labels\", f\"midasdisclabels{rater}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    ExtraTreesClassifier,\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "\n",
    "def test_multiple_models(features, labels):\n",
    "    # Define classifiers to test\n",
    "    classifiers = {\n",
    "        \"Random Forest\": RandomForestClassifier(),\n",
    "        \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "        \"SVM\": SVC(),\n",
    "        \"Logistic Regression\": LogisticRegression(),\n",
    "        \"Stochastic Gradient Descent\": SGDClassifier(),\n",
    "        \"Naive Bayes\": GaussianNB(),\n",
    "        \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "        \"Multilayer Perceptron\": MLPClassifier(),\n",
    "        \"AdaBoost\": AdaBoostClassifier(),\n",
    "        \"ExtraTrees\": ExtraTreesClassifier(),\n",
    "    }\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        features, labels, test_size=0.25, random_state=0, stratify=labels\n",
    "    )\n",
    "\n",
    "    # Test each classifier\n",
    "    f1_scores = {}\n",
    "    for name, clf in classifiers.items():\n",
    "        pipeline = Pipeline(\n",
    "            [\n",
    "                (\"variancethreshold\", VarianceFeatureReduction(threshold=0.05)),\n",
    "                (\"correlationreduction\", CorrelationFeatureReduction()),\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"classifier\", clf),\n",
    "            ]\n",
    "        )\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        f1_scores[name] = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "    # Select the classifier with the highest F1 score\n",
    "    best_classifier = max(f1_scores, key=f1_scores.get)  # type: ignore\n",
    "    print(\"Best classifier:\", best_classifier)\n",
    "    print(\"F1 score:\", f1_scores[best_classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "\n",
    "def cv(clf, features, labels):\n",
    "    # Create a stratified 5-fold cross-validation object\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    pipeline_clf = Pipeline(\n",
    "        [\n",
    "            (\"variancethreshold\", VarianceFeatureReduction(threshold=0.05)),\n",
    "            (\"correlationreduction\", CorrelationFeatureReduction()),\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"classifier\", clf),\n",
    "        ]\n",
    "    )\n",
    "    scores = cross_val_score(\n",
    "        pipeline_clf, features, labels, cv=skf, scoring=\"f1_weighted\"\n",
    "    )\n",
    "    print(f\"Cross Validation F1 Score: {scores.mean():0.4f} +/- {scores.std():0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "def imbalanced_learning_suite(features, labels):\n",
    "    # Define classifiers to test\n",
    "    classifiers = {\n",
    "        \"Balanced Bagging Classifier\": BalancedBaggingClassifier(\n",
    "            sampler=RandomUnderSampler()\n",
    "        ),\n",
    "        \"Balanced RandomForest Classifier\": BalancedRandomForestClassifier(),\n",
    "        \"RUS Boost Classifier\": RUSBoostClassifier(),\n",
    "        \"Easy Ensemble Classifier\": EasyEnsembleClassifier(),\n",
    "    }\n",
    "\n",
    "    # Create a stratified 5-fold cross-validation object\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    for name, clf in classifiers.items():\n",
    "        pipeline_clf = Pipeline(\n",
    "            [\n",
    "                (\"variancethreshold\", VarianceFeatureReduction(threshold=0.05)),\n",
    "                (\"correlationreduction\", CorrelationFeatureReduction()),\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"classifier\", clf),\n",
    "            ]\n",
    "        )\n",
    "        scores = cross_val_score(\n",
    "            pipeline_clf, features, labels, cv=skf, scoring=\"f1_weighted\"\n",
    "        )\n",
    "        print(\n",
    "            f\"{name}: {scores.mean():0.2f} f1 with a standard deviation of {scores.std():0.2f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yellowbrick.classifier as viz\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    classification_report,\n",
    ")\n",
    "from yellowbrick.style import set_palette\n",
    "\n",
    "set_palette(colors)\n",
    "\n",
    "\n",
    "def visual_metrics(clf, features, labels, classes=[\"1\", \"2\", \"3\", \"4\", \"5\"]):\n",
    "    labels_ = labels.copy()\n",
    "    if min(labels_) != 0:\n",
    "        labels_ = labels_ - min(labels_)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        features, labels_, test_size=0.25, random_state=0, stratify=labels_\n",
    "    )\n",
    "\n",
    "    _, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    labels.plot(\n",
    "        kind=\"hist\",\n",
    "        title=\"Pfirmann grade distribution\",\n",
    "        ax=axes[0],\n",
    "        xticks=[1, 2, 3, 4, 5],\n",
    "        align=\"mid\",\n",
    "    )\n",
    "\n",
    "    pipeline_clf = Pipeline(\n",
    "        [\n",
    "            (\"variancethreshold\", VarianceFeatureReduction(threshold=0.05)),\n",
    "            (\"correlationreduction\", CorrelationFeatureReduction()),\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"classifier\", clf),\n",
    "        ]\n",
    "    )\n",
    "    pipeline_clf.fit(X_train, y_train)\n",
    "    axes[1].set_title(\"Classification Report\")\n",
    "    axes[1].set_ylabel(\"Class\")\n",
    "    visualizer_class = viz.ClassificationReport(\n",
    "        pipeline_clf, classes=classes[::-1], support=True, ax=axes[1], cmap=\"Blues\"\n",
    "    )\n",
    "    visualizer_class.score(X_test, y_test)\n",
    "\n",
    "    axes[2].set_title(\"Classification Prediction Error\")\n",
    "    axes[2].set_xlabel(\"Class\")\n",
    "    axes[2].set_ylabel(\"Number of Predictions\")\n",
    "    visualizer_pred = viz.ClassPredictionError(\n",
    "        pipeline_clf, classes=classes, ax=axes[2]\n",
    "    )\n",
    "    visualizer_pred.score(X_test, y_test)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    predictions = pipeline_clf.predict(X_test)\n",
    "    print(f\"Accuracy within one grade: {accuracy_within_one(y_test, predictions):0.2f}\")\n",
    "    print(f\"Balanced accuracy: {balanced_accuracy_score(y_test, predictions):0.2f}\")\n",
    "    print(classification_report(y_test, predictions, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "def random_search(clf, distribution, features, labels):\n",
    "    pipeline_clf = Pipeline(\n",
    "        [\n",
    "            (\"variancethreshold\", VarianceFeatureReduction(threshold=0.05)),\n",
    "            (\"correlationreduction\", CorrelationFeatureReduction()),\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"classifier\", clf),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    rs_clf = RandomizedSearchCV(\n",
    "        pipeline_clf,\n",
    "        distribution,\n",
    "        cv=skf,\n",
    "        scoring=\"f1_weighted\",\n",
    "        n_iter=10,\n",
    "        random_state=0,\n",
    "    )\n",
    "    search = rs_clf.fit(features, labels)\n",
    "\n",
    "    print(f\"Best parameter (CV score={search.best_score_:0.3f}): {search.best_params_}\")\n",
    "    return {\n",
    "        key.replace(\"classifier__\", \"\"): value\n",
    "        for key, value in search.best_params_.items()\n",
    "        if key.startswith(\"classifier__\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkMaskVol(image, mask, label):\n",
    "    try:\n",
    "        imageoperations.checkMask(\n",
    "            image, mask, minimumROIDimensions=3, minimumROISize=1000, label=label\n",
    "        )\n",
    "        result = label\n",
    "    except Exception as e:\n",
    "        result = None\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_within_one(labels, predictions):\n",
    "    # Calculate the absolute difference between labels and predictions\n",
    "    diff = abs(labels - predictions)\n",
    "    # Count the number of differences that are less than or equal to one\n",
    "    correct_predictions = sum(diff <= 1)\n",
    "    # Calculate the accuracy\n",
    "    accuracy = correct_predictions / len(labels)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_path = root_dir.joinpath(\"data\", \"features\", \"t2w_improved_params.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midas_img_relation = pd.read_csv(t2_img_relation_path, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "devices = []\n",
    "for _, row in midas_img_relation.iterrows():\n",
    "    img_path = pathlib.Path(row[\"Image\"])\n",
    "    metadata_path = img_path.with_suffix(\"\").with_suffix(\".json\")\n",
    "    with open(metadata_path, \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "        manufacturer = metadata.get(\"00080070\", {}).get(\"Value\", [\"N/A\"])[0]\n",
    "        model = metadata.get(\"00081090\", {}).get(\"Value\", [\"N/A\"])[0]\n",
    "        field_strength = metadata.get(\"00180087\", {}).get(\"Value\", [\"N/A\"])[0]\n",
    "    devices.append(\n",
    "        {\n",
    "            \"Manufacturer\": manufacturer,\n",
    "            \"Model name\": model,\n",
    "            \"Field Strength\": field_strength,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Manufacturer\").value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = build_dataframe_from_csv(t2_img_relation_path, label_path(\"MODE\"), features_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "discs = {\n",
    "    \"1\": \"L5-S\",\n",
    "    \"2\": \"L4-L5\",\n",
    "    \"3\": \"L3-L4\",\n",
    "    \"4\": \"L2-L3\",\n",
    "    \"5\": \"L1-L2\",\n",
    "}\n",
    "for i in range(1, 6):\n",
    "    s = df[f\"{i}\"].value_counts()\n",
    "    s.name = discs[f\"{i}\"]\n",
    "    a.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(a).T\n",
    "\n",
    "fig = px.bar(\n",
    "    df1, title=\"Pfirrmann Grade Distribution\", color_discrete_sequence=colors\n",
    ")  # replace 0 with your column name if needed\n",
    "total_count = df1.sum(axis=1)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df1.index,\n",
    "        y=total_count,\n",
    "        mode=\"text\",\n",
    "        text=total_count,\n",
    "        textposition=\"top center\",\n",
    "        showlegend=False,\n",
    "    )\n",
    ")\n",
    "fig.update_traces(textfont_size=12)\n",
    "fig.update_xaxes(title_text=\"Pfirrmann Grade\")\n",
    "fig.update_yaxes(\n",
    "    title_text=\"Frequency\", showgrid=True, gridcolor=\"rgba(184, 184, 184, 0.3)\"\n",
    ")\n",
    "fig.update_layout(\n",
    "    plot_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    paper_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    legend_title_text=\"Intervertebral Disc\",\n",
    "    grid_rows=1,\n",
    ")\n",
    "fig.show()\n",
    "pio.write_image(fig, root_dir.joinpath(\"figures\", \"pfirrmann_grade_distribution_v2.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inter-rater agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_jd, _ = get_labels_and_features_all_discs(t2_img_relation_path, label_path(\"JDCarlos\"), features_path)\n",
    "labels_rafa, _ = get_labels_and_features_all_discs(t2_img_relation_path, label_path(\"Rafa\"), features_path)\n",
    "labels_rodro, _ = get_labels_and_features_all_discs(t2_img_relation_path, label_path(\"Rodro\"), features_path)\n",
    "\n",
    "arr = pd.concat([labels_jd, labels_rodro, labels_rafa], axis=1)\n",
    "arr.dropna(inplace=True)\n",
    "arr = arr.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cac3raters = CAC(pd.concat([labels_jd, labels_rodro, labels_rafa], axis=1))\n",
    "print(cac3raters.fleiss()[\"est\"])\n",
    "print(cac3raters.gwet()[\"est\"])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_jd.loc[(labels_jd==1).values] = 2\n",
    "labels_rodro.loc[(labels_rodro==1).values] = 2\n",
    "labels_rafa.loc[(labels_rafa==1).values] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cac3raters = CAC(pd.concat([labels_jd, labels_rodro, labels_rafa], axis=1))\n",
    "print(cac3raters.fleiss()[\"est\"])\n",
    "print(cac3raters.gwet()[\"est\"])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats import inter_rater as irr\n",
    "\n",
    "# Function to calculate Fleiss' Kappa\n",
    "def calculate_fleiss_kappa(ratings):\n",
    "    table = irr.aggregate_raters(ratings)\n",
    "    return irr.fleiss_kappa(table[0], method='fleiss')\n",
    "\n",
    "# Perform sensitivity analysis by removing one item at a time\n",
    "def sensitivity_analysis(ratings):\n",
    "    n_items = ratings.shape[0]\n",
    "    original_kappa = calculate_fleiss_kappa(ratings)\n",
    "    print(f\"Original Fleiss' Kappa: {original_kappa:.4f}\")\n",
    "    \n",
    "    kappas = []\n",
    "    for i in range(n_items):\n",
    "        subset = np.delete(ratings, i, axis=0)\n",
    "        kappa = calculate_fleiss_kappa(subset)\n",
    "        kappas.append(kappa)\n",
    "    \n",
    "    return kappas\n",
    "\n",
    "# Run sensitivity analysis\n",
    "sensitivity_kappas = sensitivity_analysis(arr)\n",
    "\n",
    "print(f\"Standard deviation: {np.std(sensitivity_kappas):.4f}\")\n",
    "\n",
    "plt.plot(range(1, len(sensitivity_kappas) + 1), sensitivity_kappas, marker='o')\n",
    "plt.axhline(y=calculate_fleiss_kappa(arr), color='r', linestyle='--', label='Original Kappa')\n",
    "plt.xlabel('Excluded Item Index')\n",
    "plt.ylabel('Fleiss\\' Kappa')\n",
    "plt.title('Sensitivity Analysis of Fleiss\\' Kappa')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cropped_discs(image_path, mask_path): \n",
    "    image = sitk.ReadImage(image_path)\n",
    "    mask = sitk.ReadImage(mask_path)\n",
    "\n",
    "    disc_segmentations = np.unique(sitk.GetArrayFromImage(mask).ravel())\n",
    "    valid_disc_segmentations = []\n",
    "    for disc_segmentation in disc_segmentations:\n",
    "        if result := checkMaskVol(image, mask, disc_segmentation):\n",
    "            valid_disc_segmentations.append(int(result))\n",
    "        if len(valid_disc_segmentations) == 5:\n",
    "            break\n",
    "\n",
    "    orient = sitk.DICOMOrientImageFilter()\n",
    "    orient.SetDesiredCoordinateOrientation(\"LPI\") # Left Posterior Inferior\n",
    "    image = orient.Execute(image)\n",
    "    mask = orient.Execute(mask)\n",
    "\n",
    "    # image = imageoperations.normalizeImage(image, scale=100)\n",
    "\n",
    "    center_slice = image.GetSize()[0] // 2\n",
    "    image = image[center_slice, ...]\n",
    "    mask = mask[center_slice, ...]\n",
    "\n",
    "    maskfilter = sitk.MaskImageFilter()\n",
    "    maskfilter.SetMaskingValue(0.0)\n",
    "    maskfilter.SetOutsideValue(np.nan)\n",
    "    masked_image = maskfilter.Execute(image, mask)\n",
    "\n",
    "    labelimfilter=sitk.LabelShapeStatisticsImageFilter()\n",
    "    labelimfilter.Execute(mask)\n",
    "\n",
    "    cropped_discs = []\n",
    "    for i in labelimfilter.GetLabels():\n",
    "        if i in valid_disc_segmentations:\n",
    "            box=labelimfilter.GetBoundingBox(i)\n",
    "            roifilter = sitk.RegionOfInterestImageFilter()\n",
    "            roifilter.SetRegionOfInterest(box)\n",
    "            cropped_discs.append(roifilter.Execute(masked_image))\n",
    "    return cropped_discs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\"Discs\": [], \"Pfirmann\": [], \"Array\": []}\n",
    "for _, row in tqdm(df.iterrows()):\n",
    "    data = {\n",
    "        \"image\": row[\"Image\"],\n",
    "        \"mask\": row[\"Mask\"],\n",
    "        \"1\": row[\"1\"],\n",
    "        \"2\": row[\"2\"],\n",
    "        \"3\": row[\"3\"],\n",
    "        \"4\": row[\"4\"],\n",
    "        \"5\": row[\"5\"],\n",
    "    }\n",
    "    cropped_discs = get_cropped_discs(row[\"Image\"], row[\"Mask\"])\n",
    "    for idx, disc in enumerate(cropped_discs, start=1):\n",
    "        results[\"Discs\"].append(idx)\n",
    "        results[\"Pfirmann\"].append(row[str(idx)])\n",
    "        disc_array = sitk.GetArrayFromImage(disc)\n",
    "        results[\"Array\"].append(disc_array[~np.isnan(disc_array)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms_df = pd.DataFrame(results)\n",
    "histograms_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 10\n",
    "\n",
    "process = histograms_df.copy()\n",
    "process[\"Scaled Array\"] = process[\"Array\"].map(\n",
    "    lambda x: (x - x.min()) / (x.max() - x.min())\n",
    ")\n",
    "process[\"Histogram\"] = process[\"Scaled Array\"].map(\n",
    "    lambda x: np.histogram(x, bins=bins)[0]\n",
    ")\n",
    "grouped_by_disc = process.groupby(\"Pfirmann\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = np.arange(0, 1.01, 1 / bins)\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(4, -1, -1):\n",
    "    plt.plot(x_[:-1], grouped_by_disc[\"Histogram\"].mean().iloc[i])\n",
    "    plt.bar(\n",
    "        x=x_[:-1],\n",
    "        height=grouped_by_disc[\"Histogram\"].mean().iloc[i],\n",
    "        width=np.diff(x_),\n",
    "        label=str(i + 1),\n",
    "    )\n",
    "plt.legend()\n",
    "# plt.ylim(0, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Plotting\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "# X, Y positions for the bars\n",
    "x_positions = x_[:-1]\n",
    "y_positions = [0, 1, 2, 3, 4]  # Different datasets on different y-positions\n",
    "\n",
    "# Width of each bar and yz-space between bars\n",
    "width = np.diff(x_)\n",
    "y_space = 0.8\n",
    "\n",
    "# Adding the histograms to the plot\n",
    "for i, hist in enumerate(grouped_by_disc[\"Histogram\"].mean()):\n",
    "    ax.bar(\n",
    "        x_positions,\n",
    "        hist,\n",
    "        zs=y_positions[i],\n",
    "        zdir=\"y\",\n",
    "        width=width,\n",
    "        align=\"center\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "\n",
    "ax.set_xlabel(\"X-axis (Value)\")\n",
    "# ax.set_ylabel('Y-axis (Dataset)')\n",
    "ax.set_zlabel(\"Z-axis (Frequency)\")\n",
    "\n",
    "# Setting the y-ticks to correspond to different datasets\n",
    "ax.set_yticks(y_positions)\n",
    "ax.set_yticklabels(\n",
    "    [\"Pfirrmann 1\", \"Pfirrmann 2\", \"Pfirrmann 3\", \"Pfirrmann 4\", \"Pfirrmann 5\"]\n",
    ")\n",
    "\n",
    "plt.title(\"3D Histograms\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intraclass correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICC_feature_reduction(\n",
    "    input_dataframe,\n",
    "    input_dataframe_ICC1,\n",
    "    input_dataframe_ICC2,\n",
    "    input_dataframe_ICC3,\n",
    "    ICC_thresh,\n",
    "):\n",
    "    import pandas as pd\n",
    "    import pingouin as pg\n",
    "    import numpy as np\n",
    "\n",
    "    # Initialize an empty flag vector\n",
    "    to_keep = []\n",
    "    # Iterate over features\n",
    "    for feature in input_dataframe.columns:\n",
    "        # Concatenate feature values vertically\n",
    "        feature_data = pd.concat(\n",
    "            [\n",
    "                input_dataframe[[feature]],\n",
    "                input_dataframe_ICC1[[feature]],\n",
    "                input_dataframe_ICC2[[feature]],\n",
    "                input_dataframe_ICC3[[feature]],\n",
    "            ],\n",
    "            axis=0,\n",
    "            ignore_index=False,\n",
    "        )\n",
    "        print(feature_data.shape)\n",
    "        # Append patient/repetition information\n",
    "        # Create a repetition/patients column\n",
    "        result_array = np.repeat(\n",
    "            [1, 2, 3, 4],\n",
    "            [\n",
    "                len(input_dataframe),\n",
    "                len(input_dataframe),\n",
    "                len(input_dataframe),\n",
    "                len(input_dataframe),\n",
    "            ],\n",
    "        )\n",
    "        feature_data[\"Repetition\"] = result_array\n",
    "        feature_data[\"Patients\"] = pd.factorize(feature_data.index)[0]\n",
    "        feature_data = feature_data.rename(columns={feature: \"FeatureValue\"})\n",
    "\n",
    "        # Compute ICC\n",
    "        icc_result = pg.intraclass_corr(\n",
    "            data=feature_data,\n",
    "            targets=\"Patients\",\n",
    "            raters=\"Repetition\",\n",
    "            ratings=\"FeatureValue\",\n",
    "        )\n",
    "        # Extract ICC value\n",
    "        icc_value = icc_result[\"ICC\"].iloc[\n",
    "            1\n",
    "        ]  # ICC2: A random sample of raters rate each target. Measure of absolute agreement.\n",
    "\n",
    "        # Check if ICC is greater than the threshold\n",
    "        if icc_value > ICC_thresh:\n",
    "            to_keep.append(True)\n",
    "        else:\n",
    "            to_keep.append(False)\n",
    "\n",
    "    return input_dataframe.loc[:, to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, features_t2 = get_labels_and_features_all_discs(t2_img_relation_path, label_path(\"AVG\"), features_path)\n",
    "features_t2.drop(index='s_8141', inplace=True)\n",
    "_, features_t2_shift = get_labels_and_features_all_discs(\n",
    "    t2_img_relation_path, \n",
    "    label_path(\"AVG\"), \n",
    "    root_dir.joinpath(\n",
    "        \"data\", \"mask_perturbation\", \"t2w_improved_params_shift.csv\"\n",
    "    )\n",
    ")\n",
    "features_t2_shift.drop(index='s_8141', inplace=True)\n",
    "_, features_t2_erode = get_labels_and_features_all_discs(\n",
    "    t2_img_relation_path, \n",
    "    label_path(\"AVG\"), \n",
    "    root_dir.joinpath(\n",
    "        \"data\", \"mask_perturbation\", \"t2w_improved_params_erode.csv\"\n",
    "    )\n",
    ")\n",
    "_, features_t2_dilate = get_labels_and_features_all_discs(\n",
    "    t2_img_relation_path, \n",
    "    label_path(\"AVG\"), \n",
    "    root_dir.joinpath(\n",
    "        \"data\", \"mask_perturbation\", \"t2w_improved_params_dilate.csv\"\n",
    "    )\n",
    ")\n",
    "features_t2_dilate.drop(index='s_8141', inplace=True)\n",
    "t2_reduced_ICC = ICC_feature_reduction(features_t2, features_t2_shift, features_t2_erode, features_t2_dilate, 0.85)\n",
    "print(f\"t2.     {t2_reduced_ICC.shape[1]} features retained from {features_t2.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_reduced_ICC.to_csv(\n",
    "    root_dir.joinpath(\n",
    "        \"data\",\n",
    "        \"mask_perturbation\",\n",
    "        \"t2w_improved_params_reduced_ICC.csv\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ICC_reduced_per_disc(disc: int):\n",
    "    t2 = pd.read_csv(\n",
    "        features_path, sep=\",\"\n",
    "    )\n",
    "    t2 = t2.loc[:, t2.columns.str.contains(f\"label{disc}\")]\n",
    "    t2 = t2[t2.select_dtypes(include=\"number\").columns.tolist()]\n",
    "\n",
    "    t2_shifted = pd.read_csv(\n",
    "        root_dir.joinpath(\n",
    "            \"data\", \"mask_perturbation\", \"t2w_improved_params_shift.csv\"\n",
    "        ),\n",
    "        sep=\",\",\n",
    "    )\n",
    "    t2_shifted = t2_shifted.loc[:, t2_shifted.columns.str.contains(f\"label{disc}\")]\n",
    "    t2_shifted = t2_shifted[t2_shifted.select_dtypes(include=\"number\").columns.tolist()]\n",
    "\n",
    "    t2_eroded = pd.read_csv(\n",
    "        root_dir.joinpath(\n",
    "            \"data\", \"mask_perturbation\", \"t2w_improved_params_erode.csv\"\n",
    "        ),\n",
    "        sep=\",\",\n",
    "    )\n",
    "    t2_eroded = t2_eroded.loc[:, t2_eroded.columns.str.contains(f\"label{disc}\")]\n",
    "    t2_eroded = t2_eroded[t2_eroded.select_dtypes(include=\"number\").columns.tolist()]\n",
    "\n",
    "    t2_dilated = pd.read_csv(\n",
    "        root_dir.joinpath(\n",
    "            \"data\", \"mask_perturbation\", \"t2w_improved_params_dilate.csv\"\n",
    "        ),\n",
    "        sep=\",\",\n",
    "    )\n",
    "    t2_dilated = t2_dilated.loc[:, t2_dilated.columns.str.contains(f\"label{disc}\")]\n",
    "    t2_dilated = t2_dilated[t2_dilated.select_dtypes(include=\"number\").columns.tolist()]\n",
    "\n",
    "    if disc == 1:\n",
    "        t2.drop(index=317, inplace=True)\n",
    "        t2_shifted.drop(index=317, inplace=True)\n",
    "        t2_eroded.drop(index=317, inplace=True)\n",
    "        t2_dilated.drop(index=317, inplace=True)\n",
    "\n",
    "    t2_reduced_ICC = ICC_feature_reduction(t2, t2_shifted, t2_eroded, t2_dilated, 0.85)\n",
    "    print(f\"t2.     {t2_reduced_ICC.shape[1]} features retained from {t2.shape[1]}\")\n",
    "\n",
    "    return t2_reduced_ICC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_1_t2_reduced_ICC = compute_ICC_reduced_per_disc(disc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_2_t2_reduced_ICC = compute_ICC_reduced_per_disc(disc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_3_t2_reduced_ICC = compute_ICC_reduced_per_disc(disc=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_4_t2_reduced_ICC = compute_ICC_reduced_per_disc(disc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_5_t2_reduced_ICC = compute_ICC_reduced_per_disc(disc=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_reduced_ICC = pd.concat(\n",
    "    [\n",
    "        disc_1_t2_reduced_ICC,\n",
    "        disc_2_t2_reduced_ICC,\n",
    "        disc_3_t2_reduced_ICC,\n",
    "        disc_4_t2_reduced_ICC,\n",
    "        disc_5_t2_reduced_ICC,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "t2_reduced_ICC.to_csv(\n",
    "    root_dir.joinpath(\n",
    "        \"data\",\n",
    "        \"mask_perturbation\",\n",
    "        \"t2w_improved_params_reduced_ICC_per_disc.csv\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Near-zero variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Feature reduction based on variance thresholding (remove features with variance smaller than 0.05)\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Initialize selector based on VarianceThreshold\n",
    "selector = VarianceThreshold(threshold=0.05)\n",
    "\n",
    "#  Estimate variances and reduce features\n",
    "selector.fit_transform(t2_reduced_ICC)\n",
    "\n",
    "# Get the selected feature labels and reduce the Radiomic_Feature dataframe\n",
    "radiomic_features_var = t2_reduced_ICC.loc[:, selector.get_support()]\n",
    "\n",
    "# Display the number of features removed\n",
    "print(\n",
    "    f\"{np.count_nonzero(~selector.get_support())}/{t2_reduced_ICC.shape[1]} features were removed due to near-zero variance.\"\n",
    ")\n",
    "\n",
    "del selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix_var = radiomic_features_var.corr(\n",
    "    method=\"spearman\"\n",
    ").abs()  # absolute correlation matrix\n",
    "\n",
    "# Initialize the flag vector with True values\n",
    "to_keep = np.full((corr_matrix_var.shape[1]), True, dtype=bool)\n",
    "\n",
    "for i in range(corr_matrix_var.shape[1]):\n",
    "    for j in range(i + 1, corr_matrix_var.shape[1]):\n",
    "        if to_keep[i] and corr_matrix_var.iloc[i, j] >= 0.8:\n",
    "            if to_keep[j]:\n",
    "                to_keep[j] = False\n",
    "\n",
    "# Retain features that are not higly correlated\n",
    "radiomic_features_corr = radiomic_features_var.iloc[:, to_keep]\n",
    "\n",
    "print(\n",
    "    f\"{np.count_nonzero(~to_keep)}/{radiomic_features_var.shape[1]} features were removed due to high correlation. {radiomic_features_corr.shape[1]} features remaining.\"\n",
    ")\n",
    "\n",
    "del to_keep, i, j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Calculate the correlation matrix of the original feature set\n",
    "corr_matrix = t2_reduced_ICC.corr(method=\"spearman\")\n",
    "# Display the correlation matrix\n",
    "plt.figure(figsize=(8, 6.5))\n",
    "sns.heatmap(corr_matrix, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "plt.title(\"Correlation of Radiomic features\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate the correlation matrix of the reduced feature set\n",
    "corr_matrix_red = radiomic_features_corr.corr(method=\"spearman\")\n",
    "# Display the correlatiradiomic_features_corron matrix\n",
    "plt.figure(figsize=(8, 6.5))\n",
    "sns.heatmap(corr_matrix_red, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "plt.title(\"Correlation of reduced radiomic features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Remaining features: {list(radiomic_features_corr.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from scipy.stats import zscore\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "\n",
    "radiomic_features_clus = copy.deepcopy(radiomic_features_corr)\n",
    "# Normalize the data\n",
    "radiomic_features_clus = zscore(radiomic_features_clus, axis=0)\n",
    "\n",
    "# Calculate and plot the clustergram\n",
    "row_linkage = hierarchy.linkage(\n",
    "    distance.pdist(radiomic_features_clus.to_numpy()), method=\"ward\"\n",
    ")\n",
    "col_linkage = hierarchy.linkage(\n",
    "    distance.pdist(radiomic_features_clus.T.to_numpy()), method=\"ward\"\n",
    ")\n",
    "g = sns.clustermap(\n",
    "    radiomic_features_clus,\n",
    "    row_linkage=row_linkage,\n",
    "    col_linkage=col_linkage,\n",
    "    method=\"ward\",\n",
    "    vmin=-3,\n",
    "    vmax=3,\n",
    "    figsize=(8, 10),\n",
    "    cmap=\"viridis\",\n",
    ")\n",
    "g.ax_cbar.set_position((0.90, 0.2, 0.03, 0.3))\n",
    "\n",
    "# Extract 5 disc degeneration clusters and append the \"Clusters\" variable to the DataFrame\n",
    "n_clusters = 5\n",
    "radiomic_features_clus[\"Clusters\"] = fcluster(\n",
    "    row_linkage, n_clusters, criterion=\"maxclust\"\n",
    ")\n",
    "\n",
    "# Print the cluster assignments\n",
    "print(\"Cluster Assignments:\", radiomic_features_clus[\"Clusters\"])\n",
    "\n",
    "del g, n_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Concatenate the target clinical variable to the radiomic DataFrame\n",
    "radiomic_features_clus = pd.concat([radiomic_features_clus, labels], axis=1)\n",
    "\n",
    "# Barplot clusters/grades\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.countplot(\n",
    "    x=\"Clusters\", hue=\"label\", data=radiomic_features_clus, palette=\"coolwarm\"\n",
    ")\n",
    "plt.title(\"Distribution of Pfirmann grade in each Cluster\")\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend(title=\"Pfirmann grade\", loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "# Perform chi-squared test\n",
    "chi2, p, _, _ = chi2_contingency(\n",
    "    pd.crosstab(radiomic_features_clus[\"label\"], radiomic_features_clus[\"Clusters\"])\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(f\"Chi-squared statistic: {chi2}\")\n",
    "print(f\"P-value: {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(root_dir.joinpath(\"data\", \"labels\", \"train.csv\"), index_col=\"ID\")\n",
    "train_features = pd.read_csv(root_dir.joinpath(\"data\", \"features\", \"scaled_train.csv\"), index_col=\"ID\")\n",
    "test_labels = pd.read_csv(root_dir.joinpath(\"data\", \"labels\", \"test.csv\"), index_col=\"ID\")\n",
    "test_features = pd.read_csv(root_dir.joinpath(\"data\", \"features\", \"scaled_test.csv\"), index_col=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classification_report_5_classes(df, save_fig=False):\n",
    "    float_int = lambda x: str(int(x)) if x > 1 else f\"{x:.2f}\"\n",
    "\n",
    "    df1 = df.iloc[:5]\n",
    "    df1_ = df1.copy()\n",
    "    df1_[\"support\"] = 0.1\n",
    "    fig = go.Figure(\n",
    "        data=go.Heatmap(\n",
    "            z=df1_.values.tolist(),\n",
    "            x=df1.columns,\n",
    "            y=[str(i) for i in range(1, 6)],\n",
    "            colorscale=[\"#ffffff\", colors[1]],\n",
    "            showscale=True,\n",
    "            xgap=1,\n",
    "            ygap=1,\n",
    "            zmin=0,\n",
    "            zmax=1,\n",
    "            hoverinfo=\"none\",\n",
    "            hoverongaps=False,\n",
    "            text=[[float_int(val) for val in row] for row in df1.values.tolist()],\n",
    "            texttemplate=\"%{text}\",\n",
    "        )\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        margin=dict(pad=10),\n",
    "        plot_bgcolor=\"rgba(0,0,0,0)\",\n",
    "        legend_title_text=\"Intervertebral Disc\",\n",
    "        grid_rows=1,\n",
    "        title=\"Per grade classification results for the five level grading task\",\n",
    "    )\n",
    "    fig.update_xaxes(\n",
    "        automargin=True,\n",
    "        tickvals=list(range(len(df1.columns))),\n",
    "        ticktext=[col.capitalize() for col in df1.columns],\n",
    "        showgrid=False,\n",
    "    )\n",
    "    fig.update_yaxes(automargin=True, title_text=\"Pfirrmann Grade\", showgrid=False)\n",
    "    fig.update_traces(\n",
    "        textfont_size=16,\n",
    "    )\n",
    "    fig.show()\n",
    "    if save_fig:\n",
    "        fig.write_image(root_dir.joinpath(\"figures\", \"per_grade_5_levels_v2.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_prediction_error_5_classes(df, save_fig=False):    \n",
    "    fig = px.bar(\n",
    "        df, title=\"Class Prediction Error\", color_discrete_sequence=colors\n",
    "    )  # replace 0 with your column name if needed\n",
    "\n",
    "    total_count = df.sum(axis=1)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df.index,\n",
    "            y=total_count,\n",
    "            mode=\"text\",\n",
    "            text=total_count,\n",
    "            textposition=\"top center\",\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "    fig.update_traces(textfont_size=12)\n",
    "    fig.update_xaxes(title_text=\"Predicted Pfirrmann Grade\")\n",
    "    fig.update_yaxes(\n",
    "        title_text=\"Frequency\", showgrid=True, gridcolor=\"rgba(184, 184, 184, 0.3)\"\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        plot_bgcolor=\"rgba(0,0,0,0)\",\n",
    "        legend_title_text=\"True Pfirrmann Grade\",\n",
    "        grid_rows=1,\n",
    "    )\n",
    "    fig.show()\n",
    "    if save_fig:\n",
    "        fig.write_image(root_dir.joinpath(\"figures\", \"class_prediction_error_5level_v2.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lr_feature_importance(lr_model, feature_names, save_fig=False):\n",
    "    feature_importances = lr_model.coef_[0]\n",
    "\n",
    "    # Sort the feature importances in descending order\n",
    "    sorted_indices = feature_importances.argsort()[::-1]\n",
    "    sorted_indices = list(sorted_indices[:10])+list(sorted_indices[-10:])\n",
    "    sorted_features = [feature_names[i]+\"   \" for i in sorted_indices]\n",
    "    sorted_importances = feature_importances[sorted_indices]\n",
    "\n",
    "    # Create a trace for the feature importance bar plot\n",
    "    trace = go.Bar(\n",
    "        x=sorted_importances,\n",
    "        y=sorted_features,\n",
    "        orientation='h',\n",
    "        marker=dict(\n",
    "            color=sorted_importances,\n",
    "            colorscale=colors,\n",
    "            reversescale=True\n",
    "        ),\n",
    "        text=sorted_importances.round(2),\n",
    "        textposition='outside',\n",
    "        hoverinfo='text',\n",
    "        opacity=0.8\n",
    "    )\n",
    "\n",
    "    # Create the layout for the plot\n",
    "    layout = go.Layout(\n",
    "        title='Feature Importance (Top 10 positive and negative)',\n",
    "        xaxis=dict(title='Importance'),\n",
    "        yaxis=dict(title='Feature', tickangle=-35),\n",
    "        width=1000,\n",
    "        height=600,\n",
    "        plot_bgcolor=\"rgba(0,0,0,0)\",\n",
    "        grid_rows=1,\n",
    "    )\n",
    "\n",
    "    # Create the figure and plot it\n",
    "    fig = go.Figure(data=[trace], layout=layout)\n",
    "    fig.show()\n",
    "    if save_fig:\n",
    "        fig.write_image(root_dir.joinpath(\"figures\", \"feature_importance_5level.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visual_metrics(\n",
    "    clf, \n",
    "    params, \n",
    "    train_features, \n",
    "    train_labels, \n",
    "    test_features, \n",
    "    test_labels, \n",
    "    plot_classification_report=plot_classification_report_5_classes,\n",
    "    plot_class_prediction_error=plot_class_prediction_error_5_classes,\n",
    "    save_fig=False\n",
    "):\n",
    "    pipeline_clf = Pipeline(\n",
    "        [\n",
    "            (\"reduce_dim\", \"passthrough\"),\n",
    "            (\"classifier\", clf),\n",
    "        ]\n",
    "    )\n",
    "    pipeline_clf.set_params(**params).fit(train_features, train_labels)\n",
    "\n",
    "    plot_lr_feature_importance(pipeline_clf.named_steps[\"classifier\"], train_features.columns.values, save_fig)\n",
    "\n",
    "    # # Predict the values for the test set\n",
    "    # y_pred = pipeline_clf.predict(test_features)\n",
    "\n",
    "    # # Generate a classification report\n",
    "    # report = classification_report(test_labels, y_pred, output_dict=True)\n",
    "\n",
    "    # # Convert the report to a DataFrame\n",
    "    # df_classification_report = pd.DataFrame(report).transpose()\n",
    "\n",
    "    # test_labels_ = test_labels.reset_index(drop=True)\n",
    "    # test_labels_[\"Predicted\"] = pd.Series(y_pred, name=\"Predicted\")\n",
    "    # df_class_prediction_error = test_labels_.astype(int)\n",
    "    # df_class_prediction_error = df_class_prediction_error.groupby(\"Predicted\").value_counts().unstack()\n",
    "\n",
    "    # predictions = [y_pred]\n",
    "    # for image_type in [\"original\", \"log\", \"wavelet\"]:\n",
    "    #     X_train = train_features.loc[:,train_features.columns.str.contains(image_type) & ~train_features.columns.str.contains(\"diagnostics\")].copy()\n",
    "    #     X_test = test_features.loc[:,test_features.columns.str.contains(image_type) & ~test_features.columns.str.contains(\"diagnostics\")].copy()\n",
    "    #     pipeline_clf.set_params(**params).fit(X_train, train_labels)\n",
    "    #     predictions.append(pipeline_clf.predict(X_test))\n",
    "    \n",
    "    # plot_classification_report(df_classification_report, save_fig)\n",
    "    # plot_class_prediction_error(df_class_prediction_error, save_fig)\n",
    "    # print(f\"Accuracy within one grade: {accuracy_within_one(test_labels['label'], y_pred):0.2f}\")\n",
    "    # print(f\"Balanced accuracy: {balanced_accuracy_score(test_labels['label'], y_pred):0.2f}\")\n",
    "    # cac_image_type = CAC(pd.DataFrame(np.vstack(predictions).T))\n",
    "    # print(cac_image_type.fleiss()[\"est\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All discs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "params = {\n",
    "    \"classifier__solver\": \"liblinear\",\n",
    "    \"classifier__penalty\": \"l2\",\n",
    "    \"classifier__max_iter\": 300,\n",
    "    \"classifier__C\": 10.0,\n",
    "}\n",
    "visual_metrics(clf, params, train_features, train_labels, test_features, test_labels, save_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visual_metrics_per_disc(clf, params, disc, train_features, train_labels, test_features, test_labels):\n",
    "    y_train = train_labels.loc[\n",
    "        train_labels.index.str.endswith(disc)\n",
    "    ]\n",
    "    X_train = train_features.loc[\n",
    "        train_features.index.str.endswith(disc)\n",
    "    ]\n",
    "    y_test = test_labels.loc[\n",
    "        test_labels.index.str.endswith(disc)\n",
    "    ]\n",
    "    X_test = test_features.loc[\n",
    "        test_features.index.str.endswith(disc)\n",
    "    ]\n",
    "    visual_metrics(clf, params, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Disc 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = \"1\"\n",
    "clf = LogisticRegression()\n",
    "params = {\n",
    "    \"reduce_dim\": PCA(n_components=0.95, random_state=0),\n",
    "    \"classifier__solver\": \"sag\",\n",
    "    \"classifier__penalty\": \"l2\",\n",
    "    \"classifier__max_iter\": 200,\n",
    "    \"classifier__C\": 1.0,\n",
    "}\n",
    "visual_metrics_per_disc(clf, params, disc, train_features, train_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disc 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = \"2\"\n",
    "clf = GradientBoostingClassifier()\n",
    "params = {\n",
    "    \"classifier__subsample\": 1.0,\n",
    "    \"classifier__n_estimators\": 200,\n",
    "    \"classifier__max_features\": \"sqrt\",\n",
    "    \"classifier__max_depth\": 4,\n",
    "    \"classifier__learning_rate\": 0.1,\n",
    "}\n",
    "visual_metrics_per_disc(clf, params, disc, train_features, train_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disc 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = \"3\"\n",
    "clf = MLPClassifier()\n",
    "params = {\n",
    "    \"reduce_dim\": mRMRFeatureReduction(K=20),\n",
    "    \"classifier__solver\": \"adam\",\n",
    "    \"classifier__learning_rate\": \"adaptive\",\n",
    "    \"classifier__hidden_layer_sizes\": (50, 50),\n",
    "    \"classifier__alpha\": 0.01,\n",
    "    \"classifier__activation\": \"relu\",\n",
    "}\n",
    "visual_metrics_per_disc(clf, params, disc, train_features, train_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disc 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = \"4\"\n",
    "clf = GradientBoostingClassifier()\n",
    "params = {\n",
    "    \"reduce_dim\": mRMRFeatureReduction(K=20),\n",
    "    \"classifier__subsample\": 0.7,\n",
    "    \"classifier__n_estimators\": 100,\n",
    "    \"classifier__max_features\": \"log2\",\n",
    "    \"classifier__max_depth\": 2,\n",
    "    \"classifier__learning_rate\": 0.1,\n",
    "}\n",
    "visual_metrics_per_disc(clf, params, disc, train_features, train_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disc 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = \"5\"\n",
    "clf = MLPClassifier()\n",
    "params = {\n",
    "    \"reduce_dim\": mRMRFeatureReduction(K=20),\n",
    "    \"classifier__solver\": \"adam\",\n",
    "    \"classifier__learning_rate\": \"constant\",\n",
    "    \"classifier__hidden_layer_sizes\": (50, 50),\n",
    "    \"classifier__alpha\": 0.01,\n",
    "    \"classifier__activation\": \"tanh\",\n",
    "}\n",
    "visual_metrics_per_disc(clf, params, disc, train_features, train_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining classes 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.loc[(train_labels==1).values] = 2\n",
    "test_labels.loc[(test_labels==1).values] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classification_report_4_classes(df, save_fig=False):\n",
    "    float_int = lambda x: str(int(x)) if x > 1 else f\"{x:.2f}\"\n",
    "\n",
    "    df1_ = df.iloc[:4].copy()\n",
    "    df1_[\"support\"] = 0.1\n",
    "    fig = go.Figure(\n",
    "        data=go.Heatmap(\n",
    "            z=df1_.values.tolist(),\n",
    "            x=df1.columns,\n",
    "            y=[\"1 and 2\", \"3\", \"4\", \"5\"],\n",
    "            colorscale=[\"#ffffff\", colors[4]],\n",
    "            zmin=0,\n",
    "            zmax=1,\n",
    "            showscale=True,\n",
    "            xgap=1,\n",
    "            ygap=1,\n",
    "            text=[[float_int(val) for val in row] for row in df.iloc[:4].values.tolist()],\n",
    "            texttemplate=\"%{text}\",\n",
    "        )\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        margin=dict(pad=10),  # padding\n",
    "        plot_bgcolor=\"rgba(0,0,0,0)\",\n",
    "        legend_title_text=\"Intervertebral Disc\",\n",
    "        grid_rows=1,\n",
    "        title=\"Per grade classification results for the four level grading task\",\n",
    "    )\n",
    "    fig.update_xaxes(\n",
    "        automargin=True,\n",
    "        tickvals=list(range(len(df1.columns))),\n",
    "        ticktext=[col.capitalize() for col in df1_.columns],\n",
    "        showgrid=False,\n",
    "    )\n",
    "    fig.update_yaxes(automargin=True, title_text=\"Pfirrmann Grade\", showgrid=False)\n",
    "    fig.update_traces(\n",
    "        textfont_size=16,\n",
    "    )\n",
    "    fig.show()\n",
    "    if save_fig:\n",
    "        fig.write_image(root_dir.joinpath(\"figures\", \"per_grade_4_levels_v2.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_prediction_error_4_classes(df, save_fig=False):\n",
    "    fig = px.bar(\n",
    "        df, title=\"Class Prediction Error\", color_discrete_sequence=colors\n",
    "    )  # replace 0 with your column name if needed\n",
    "\n",
    "    for name, trace in zip([\"1 and 2\", \"3\", \"4\", \"5\"], fig.data):\n",
    "        trace.name = name\n",
    "\n",
    "    total_count = df.sum(axis=1)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df.index,\n",
    "            y=total_count,\n",
    "            mode=\"text\",\n",
    "            text=total_count,\n",
    "            textposition=\"top center\",\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "    fig.update_traces(textfont_size=12)\n",
    "    fig.update_xaxes(\n",
    "        title_text=\"Predicted Pfirrmann Grade\",\n",
    "        tickvals=list(range(2, 6)),\n",
    "        ticktext=[\"1 and 2\", \"3\", \"4\", \"5\"],\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        title_text=\"Frequency\", showgrid=True, gridcolor=\"rgba(184, 184, 184, 0.3)\"\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        plot_bgcolor=\"rgba(0,0,0,0)\",\n",
    "        legend_title_text=\"True Pfirrmann Grade\",\n",
    "        grid_rows=1,\n",
    "    )\n",
    "    fig.show()\n",
    "    if save_fig:\n",
    "        fig.write_image(root_dir.joinpath(\"figures\", \"class_prediction_error_4level_v2.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All discs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel=\"linear\")\n",
    "params = {\"classifier__gamma\": \"scale\", \"classifier__C\": 1}\n",
    "visual_metrics(clf, \n",
    "               params, \n",
    "               train_features, \n",
    "               train_labels, \n",
    "               test_features, \n",
    "               test_labels,\n",
    "               plot_classification_report_4_classes,\n",
    "               plot_class_prediction_error_4_classes,\n",
    "               save_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visual_metrics_per_disc(clf, params, disc, train_features, train_labels, test_features, test_labels):\n",
    "    y_train = train_labels.loc[\n",
    "        train_labels.index.str.endswith(disc)\n",
    "    ]\n",
    "    X_train = train_features.loc[\n",
    "        train_features.index.str.endswith(disc)\n",
    "    ]\n",
    "    y_test = test_labels.loc[\n",
    "        test_labels.index.str.endswith(disc)\n",
    "    ]\n",
    "    X_test = test_features.loc[\n",
    "        test_features.index.str.endswith(disc)\n",
    "    ]\n",
    "    visual_metrics(clf, \n",
    "                   params, \n",
    "                   X_train, \n",
    "                   y_train,  \n",
    "                   X_test,\n",
    "                   y_test,\n",
    "                   plot_classification_report_4_classes,\n",
    "                   plot_class_prediction_error_4_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disc 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = \"1\"\n",
    "clf = SVC(kernel=\"linear\")\n",
    "params = {\n",
    "    \"reduce_dim\": PCA(n_components=0.95, random_state=0),\n",
    "    \"classifier__gamma\": \"scale\",\n",
    "    \"classifier__C\": 1,\n",
    "}\n",
    "visual_metrics_per_disc(clf, params, disc, train_features, train_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disc 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = \"2\"\n",
    "clf = GradientBoostingClassifier()\n",
    "params = {\n",
    "    \"classifier__subsample\": 1.0,\n",
    "    \"classifier__n_estimators\": 500,\n",
    "    \"classifier__max_features\": \"sqrt\",\n",
    "    \"classifier__max_depth\": 2,\n",
    "    \"classifier__learning_rate\": 0.2,\n",
    "}\n",
    "visual_metrics_per_disc(clf, params, disc, train_features, train_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disc 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = \"3\"\n",
    "clf = MLPClassifier()\n",
    "params = {\n",
    "    \"reduce_dim\": mRMRFeatureReduction(K=20),\n",
    "    \"classifier__solver\": \"adam\",\n",
    "    \"classifier__learning_rate\": \"constant\",\n",
    "    \"classifier__hidden_layer_sizes\": (50, 50),\n",
    "    \"classifier__alpha\": 0.0001,\n",
    "    \"classifier__activation\": \"relu\",\n",
    "}\n",
    "visual_metrics_per_disc(clf, params, disc, train_features, train_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disc 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = \"4\"\n",
    "clf = GradientBoostingClassifier()\n",
    "params = {\n",
    "    \"reduce_dim\": mRMRFeatureReduction(K=10),\n",
    "    \"classifier__subsample\": 0.9,\n",
    "    \"classifier__n_estimators\": 500,\n",
    "    \"classifier__max_features\": \"sqrt\",\n",
    "    \"classifier__max_depth\": 4,\n",
    "    \"classifier__learning_rate\": 0.05,\n",
    "}\n",
    "visual_metrics_per_disc(clf, params, disc, train_features, train_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disc 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = \"5\"\n",
    "clf = MLPClassifier()\n",
    "params = {\n",
    "    \"reduce_dim\": PCA(n_components=0.99, random_state=0),\n",
    "    \"classifier__solver\": \"adam\",\n",
    "    \"classifier__learning_rate\": \"invscaling\",\n",
    "    \"classifier__hidden_layer_sizes\": (50,),\n",
    "    \"classifier__alpha\": 0.0001,\n",
    "    \"classifier__activation\": \"tanh\",\n",
    "}\n",
    "visual_metrics_per_disc(clf, params, disc, train_features, train_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radiomics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
